
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>13. Equivariant Neural Networks &#8212; Deep Learning for Molecules and Materials</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/custom.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="14. Natural Language Processing" href="NLP.html" />
    <link rel="prev" title="12. Normalizing Flows" href="flows.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning for Molecules and Materials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Overview
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  A. Math Review
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../math/tensors-and-shapes.html">
   1. Tensors and Shapes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  B. Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/introduction.html">
   2. Introduction to Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/regression.html">
   3. Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/classification.html">
   4. Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml/kernel.html">
   5. Kernel Learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  C. Deep Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   6. Introduction to Deep Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="layers.html">
   7. Standard Layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gnn.html">
   8. Graph Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="attention.html">
   9. Attention Layers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="data.html">
   10. Input Data &amp; Equivariances
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="VAE.html">
   11. Variational Autoencoder
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="flows.html">
   12. Normalizing Flows
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   13. Equivariant Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NLP.html">
   14. Natural Language Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="xai.html">
   15. Interpretability in Deep Learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  D. Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../applied/QM9.html">
   16. Predicting DFT Energies with GNNs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../applied/MolGenerator.html">
   17. Generative RNN in Browser
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <script async defer src="https://scripts.simpleanalyticscdn.com/latest.js"></script><noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript> By <a href="https://twitter.com/andrewwhite01">Andrew White</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/dl/Equivariant.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/whitead/dmol-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/whitead/dmol-book/master?urlpath=tree/dl/Equivariant.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/whitead/dmol-book/blob/master/dl/Equivariant.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#do-you-need-equivariance">
   13.1. Do you need equivariance?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-this-notebook">
   13.2. Running This Notebook
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#outline">
     13.2.1. Outline
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-theory">
   13.3. Group Theory
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#finite-group-z-6">
     13.3.1. ⬡ Finite Group
     <span class="math notranslate nohighlight">
      \(Z_6\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#p4m">
     13.3.2. ▩ p4m
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#so-3-lie-group">
     13.3.3. ⚽ SO(3) Lie Group
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#groups-on-spaces">
     13.3.4. Groups on Spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariance-definition">
   13.4. Equivariance Definition
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolution-layers">
   13.5. G-Equivariant Convolution Layers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-between-space-and-group">
   13.6. Converting between Space and Group
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-on-finite-groups">
   13.7. G-Equivariant Convolutions on Finite Groups
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#g-equivariant-convolutions-with-translation">
   13.8. G-Equivariant Convolutions with Translation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#group-representation">
   13.9. Group Representation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#irreducible-representations">
     13.9.1. Irreducible representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#equivariant-neural-networks-with-constraints">
   13.10. Equivariant Neural Networks with Constraints
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-the-constraints-work">
     13.10.1. How the constraints work
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#including-permutation-groups">
     13.10.2. Including Permutation Groups
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chapter-summary">
   13.11. Chapter Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relevant-videos">
   13.12. Relevant Videos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#intro-to-geometric-deep-learning">
     13.12.1. Intro to Geometric Deep Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equivariant-networks">
     13.12.2. Equivariant Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cited-references">
   13.13. Cited References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="equivariant-neural-networks">
<h1><span class="section-number">13. </span>Equivariant Neural Networks<a class="headerlink" href="#equivariant-neural-networks" title="Permalink to this headline">¶</a></h1>
<p>The previous chapter <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> discussed data transformation and network architecture decisions that can be made to make a neural network equivariant with respect to translation, rotation, and permutations. However, those ideas limit the expressibility of our networks and are constructed ad-hoc. Now we will take a more systematic approach to defining equivariances and prove that there is only one layer type that can preserve a given equivariance. The result of this section will be layers that can be equivariant with respect to any transform, even for more esoteric cases like points on a sphere or mirror operations. To achieve this, we will need tools from group theory, representation theory, harmonic analysis, and deep learning. Equivariant neural networks are part of a broader topic of <strong>geometric deep learning</strong>, which is learning with data that has some underlying geometric relationships. Geometric deep learning is thus a broad-topic and includes the “5Gs”: grids, groups, graphs, geodesics, and gauges. However, you’ll see papers with that nomenclature concentrated on point clouds (gauges), whereas graph learning and grids are usually called graph neural networks and convolutions neural networks respectively.</p>
<div class="section" id="do-you-need-equivariance">
<h2><span class="section-number">13.1. </span>Do you need equivariance?<a class="headerlink" href="#do-you-need-equivariance" title="Permalink to this headline">¶</a></h2>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>I’m being a bit unfair, these papers have some slightly different application areas (lie vs compact vs finite groups) and differ mostly in their non-linearity.</p>
</div>
<p>Before we get too far, let me first try to talk you out of equivariant networks. The math required is advanced, especially because the theory of these is still in flux. There are five papers in the last few years that propose a general theory for equivariant networks and they each take a slightly different approach <span id="id1">[<a class="reference internal" href="#id103">FSIW20</a>, <a class="reference internal" href="#id101">CGW19</a>, <a class="reference internal" href="#id100">KT18</a>, <a class="reference internal" href="#id113">LW20</a>, <a class="reference internal" href="#id145">FWW21</a>]</span>. It is also easy to make mistakes in implementations due to the complexity of the methods. You also must do implementations (as of early 2021) because there are no efficient general implementations for equivariant networks. You will also find that equivariant networks do not generally beat state of the art models on many of the tasks they’re designed for – although that is now quickly changing at the end of 2020 with recent benchmarks set in point cloud segmentation <span id="id2">[<a class="reference internal" href="#id106">WAR20</a>]</span>, molecular force field prediction <span id="id3">[<a class="reference internal" href="#id107">BSS+21</a>]</span>, molecular energy predictions <span id="id4">[<a class="reference internal" href="#id108">KGrossGunnemann20b</a>]</span>, and 3D molecular structure generation <span id="id5">[<a class="reference internal" href="#id157">SHF+21</a>]</span>.</p>
<p>Alternatives to equivariant networks are training and testing augmentation. Both are powerful methods for many domains and are easy to implement. However, they do not work for locally compact symmetry groups (e.g., SO(3)), so you cannot use them for rotationally equivariant data. You can do data transformations like discussed in <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> to avoid equivariance. So why would you study this chapter? I think these ideas are important and incorporating the equivariant layers into other network architectures can dramatically reduce parameter numbers and increase training efficiency.</p>
</div>
<div class="section" id="running-this-notebook">
<h2><span class="section-number">13.2. </span>Running This Notebook<a class="headerlink" href="#running-this-notebook" title="Permalink to this headline">¶</a></h2>
<p>Click the  <i aria-label="Launch interactive content" class="fas fa-rocket"></i>  above to launch this page as an interactive Google Colab. See details below on installing packages, either on your own environment or on Google Colab</p>
<div class="dropdown admonition tip">
<p class="admonition-title">Tip</p>
<p>To install packages, execute this code in a new cell</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install matplotlib numpy pandas seaborn jax jaxlib emlp==1.02 dm-haiku
</pre></div>
</div>
</div>
<div class="section" id="outline">
<h3><span class="section-number">13.2.1. </span>Outline<a class="headerlink" href="#outline" title="Permalink to this headline">¶</a></h3>
<p>We have to lay some mathematical foundations before we can grasp the equations and details of equivariant networks. We’ll start with a brief overview of group theory so we can define the principle of equivariance generally. Then we’ll show how any equivariance can be enforced in a neural network via a generalization of convolutions. Then we’ll visit representation theory to see how to encode groups into matrices.  Then we’ll see how these convolutions can be more easily represented using the generalization of Fourier transforms. Finally, we’ll examine some implementations. Throughout this chapter we’ll see three examples that capture some of the different settings.</p>
</div>
</div>
<div class="section" id="group-theory">
<h2><span class="section-number">13.3. </span>Group Theory<a class="headerlink" href="#group-theory" title="Permalink to this headline">¶</a></h2>
<p>A modern treatment of group theory can be found in <span id="id6">[<a class="reference internal" href="#id110">Zee16</a>]</span>. You can watch a short fun primer video on group theory from <a class="reference external" href="https://www.youtube.com/watch?v=mH0oCDa74tE">3Blue1Brown here</a>.</p>
<p>A group is a general object in mathematics. A group is a set of elements that can be combined in a binary operation whose output is another member of the group. The most common example are the integers. If you combine two integers in a binary operation, the output is another integer. Of course, it depends on the operation (<span class="math notranslate nohighlight">\(1 \div 2\)</span> does not give an integer), so specifically consider addition. Integers are not the example we care about though. We’re interested in groups of <strong>transformations</strong> that move points in a space. Operations like rotation, scaling, mirroring, or translating of single points. As you read about groups here, remember that the elements of the groups are <em>not</em> numbers or points. The group elements are transformations that act on points in the space. Notice I’m being a bit nebulous on what the space is for now. Let’s first define a group:</p>
<div class="admonition-group-definition admonition">
<p class="admonition-title">Group Definition</p>
<p>A group <span class="math notranslate nohighlight">\(G\)</span> is a set of elements (e.g., <span class="math notranslate nohighlight">\(\{a, b, c, i, e\}\)</span>) equipped with a binary operation (<span class="math notranslate nohighlight">\(a\cdot{}b = c\)</span>) whose output is another group element and the following conditions are satisfied:</p>
<ol class="simple">
<li><p><strong>Closure</strong> The output of the binary operation is always a member of the group</p></li>
<li><p><strong>Associativity</strong> <span class="math notranslate nohighlight">\((a\cdot{}b)\cdot{}c = a\cdot{}(b\cdot{}c)\)</span></p></li>
<li><p><strong>Identity</strong> There is a single identity element <span class="math notranslate nohighlight">\(e\)</span> such that <span class="math notranslate nohighlight">\(ex = x \forall x \in G\)</span></p></li>
<li><p><strong>Inverse</strong> There exists exactly one inverse element <span class="math notranslate nohighlight">\(i\)</span> for each <span class="math notranslate nohighlight">\(x\)</span> such that <span class="math notranslate nohighlight">\(xi = e\)</span></p></li>
</ol>
</div>
<p>This is quite a bit of nice structure. We always have an inverse available. Applying the binary operations never accidentally leaves our group. One important property that is missing from this list is <strong>commutativity</strong>. In general, a group is not commutative so that <span class="math notranslate nohighlight">\(a\cdot{}b \neq b\cdot{}a\)</span>. If the group does have this extra property, we call the group <strong>abelian</strong>. Another detail is how big the set is. It can indeed be infinite, which is why the integers or all possible rotations of a sphere can be represented as a group. One notational convenience we’ll make is that the binary operation “<span class="math notranslate nohighlight">\(\cdot{}\)</span>” will just be referred to as multiplication. The number of elements in a group <span class="math notranslate nohighlight">\(|G|\)</span> is known as the <strong>order</strong>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>If you multiply two transforms <span class="math notranslate nohighlight">\(a\cdot{}b\)</span>, we always apply <span class="math notranslate nohighlight">\(b\)</span> first and then <span class="math notranslate nohighlight">\(a\)</span>. This is important to remember for non-commutative groups (non-abelian).</p>
</div>
<p>The point of introducing the groups is so that they can transforms elements of our space. This is done through a <strong>group action</strong></p>
<div class="admonition-group-action admonition">
<p class="admonition-title">Group Action</p>
<p>A group action <span class="math notranslate nohighlight">\(\phi(g, v)\)</span> is a mapping from a group <span class="math notranslate nohighlight">\(G\)</span> and a space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-11cc351b-f0b2-4f9d-9380-ad6659c715b4">
<span class="eqno">(13.1)<a class="headerlink" href="#equation-11cc351b-f0b2-4f9d-9380-ad6659c715b4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\phi: G\times \mathcal{X}\rightarrow \mathcal{X}
\end{equation}\]</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title">function arrow</p>
<p><span class="math notranslate nohighlight">\(G\times \mathcal{X}\)</span> means there are two input arguments, one from group <span class="math notranslate nohighlight">\(G\)</span> and one from space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. <span class="math notranslate nohighlight">\(\rightarrow \mathcal{X}\)</span> shows our function outputs a value in the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>.</p>
</div>
<p>So a group action takes in two arguments (binary): a group element and a point in a space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and transforms the point to a new one: <span class="math notranslate nohighlight">\(\phi(g, x_0) = x_1\)</span>. This is just a more systematic way of saying it transforms a point. The group action is neither unique to the space nor group. Often we’ll omit the function notation for the group action and just write <span class="math notranslate nohighlight">\(gx = x'\)</span>.</p>
<p>Let’s introduce our three example groups that we’ll refer to throughout this chapter.</p>
<div class="section" id="finite-group-z-6">
<h3><span class="section-number">13.3.1. </span>⬡ Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span><a class="headerlink" href="#finite-group-z-6" title="Permalink to this headline">¶</a></h3>
<p>The first group is about rotations of a hexagon <span class="pasted-inline"><img alt="../_images/Equivariant_80_6.png" src="../_images/Equivariant_80_6.png" /></span>. Our basic group member will be rotating the hexagon enough to shift all the vertices: <span class="pasted-inline"><img alt="../_images/Equivariant_80_0.png" src="../_images/Equivariant_80_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_1.png" src="../_images/Equivariant_80_1.png" /></span>. Notice I’ve colored the vertices and added a line so we can easily distinguish the orientation of the hexagon. Remember the hexagon, its colors, and if it is actually symmetric have nothing to do with the group. <em>The group elements are transformations we apply to the hexagon</em>.</p>
<p>One group action for this example can use modular arithmetic. If we represent a point in our space as <span class="math notranslate nohighlight">\(\left\{0,\ldots, 5\right\}\)</span> then the rotation transformation is <span class="math notranslate nohighlight">\(x' = x + 1 \;(\bmod\; 6)\)</span>. For example, if we start at <span class="math notranslate nohighlight">\(5\)</span> and rotate, we get back to <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Our group must contain our rotation transformation <span class="math notranslate nohighlight">\(r\)</span> and the identity: <span class="math notranslate nohighlight">\(\{e, r\}\)</span>. This set is not closed though: rotating twice <span class="math notranslate nohighlight">\(r\cdot{}r\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_0.png" src="../_images/Equivariant_80_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_1.png" src="../_images/Equivariant_80_1.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_2.png" src="../_images/Equivariant_80_2.png" /></span> gives a new group element <span class="math notranslate nohighlight">\(r^2\)</span>. To close the group we need to have <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, r^4, r^5\}\)</span>.</p>
<p>Is this closed? Consider rotating twice and then five times <span class="math notranslate nohighlight">\(r^5\cdot{}r^2\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_0.png" src="../_images/Equivariant_80_0.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_2.png" src="../_images/Equivariant_80_2.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_1.png" src="../_images/Equivariant_80_1.png" /></span> You can see that this is the same as <span class="math notranslate nohighlight">\(r\)</span>, so <span class="math notranslate nohighlight">\(r^5\cdot{}r^2 = r\)</span>. What about the inverses element? The inverse of <span class="math notranslate nohighlight">\(r\)</span> is <span class="math notranslate nohighlight">\(r^5\)</span>. <span class="math notranslate nohighlight">\(r\cdot{}r^5 = e\)</span>. You can indeed see that each element has an inverse (<span class="math notranslate nohighlight">\(e\)</span> is its own inverse).</p>
<p>In general, we can write out the group as a multiplication table that conveys all group elements and defines the output of all binary outputs:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l|cccccr}
&amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5\\
\hline
e &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5\\
r &amp; r &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e\\
r^2 &amp; r^2 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e &amp; r\\
r^3 &amp; r^3 &amp; r^4 &amp; r^5 &amp; e &amp; r &amp; r^2\\
r^4 &amp; r^4 &amp; r^5 &amp; e &amp; r &amp; r^2 &amp; r^3\\
r^5 &amp; r^5 &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; r^4\\
\end{array}
\end{split}\]</div>
<p>You can also see that the group is abelian (commutative). For example, <span class="math notranslate nohighlight">\(r\cdot{}r^3 = r^3\cdot{}r\)</span>.</p>
<p>This kind of table is called a <a class="reference external" href="https://en.wikipedia.org/wiki/Cayley_table"><strong>Cayley table</strong></a>. Although it doesn’t matter for this example, we’ll see later that the order of look-up matters. Specifically if our group is non-abelian. <em>The row factor comes first and the column factor second</em>. So <span class="math notranslate nohighlight">\(r\cdot{}r^5\)</span> means we look at row <span class="math notranslate nohighlight">\(r\)</span> and column <span class="math notranslate nohighlight">\(r^5\)</span> to get the group element, which in this case is <span class="math notranslate nohighlight">\(e\)</span>.</p>
<p>This group of rotations is an example of a <strong>cyclic group</strong> and is isomorphic (same transofmrations, but operates on different objects) to integers modulo 6. Meaning, you could view rotation <span class="math notranslate nohighlight">\(r^n\)</span> as operating on integers <span class="math notranslate nohighlight">\((x + n) \textrm{mod}\, 6\)</span>. Cyclic groups are written as <span class="math notranslate nohighlight">\(Z_n\)</span>, so this group is <span class="math notranslate nohighlight">\(Z_6\)</span>.</p>
</div>
<div class="section" id="p4m">
<h3><span class="section-number">13.3.2. </span>▩ p4m<a class="headerlink" href="#p4m" title="Permalink to this headline">¶</a></h3>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>p4m strictly speaking only includes integer translations but many of the principles apply for continuous infinite groups (locally compact) and integer (countably) infinite groups</p>
</div>
<p>The second group contains translation, 90° rotations, and  horizontal/vertical mirroring. We’re now operating on real numbers <span class="math notranslate nohighlight">\(x,y\)</span>, so we’re in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>. Let’s ignore the translation for now and just consider mirroring (<span class="math notranslate nohighlight">\(s\)</span>) and rotation by 90° (<span class="math notranslate nohighlight">\(r\)</span>) about the origin. What powers of <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(s\)</span> do we need to have a closed group? Considering rotations alone first, like last time we should only need up to <span class="math notranslate nohighlight">\(r^3\)</span>. Here are the rotations visually: <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_12.png" src="../_images/Equivariant_80_12.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_16.png" src="../_images/Equivariant_80_16.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_20.png" src="../_images/Equivariant_80_20.png" /></span> What about mirroring on horizontal/vertical? Mirroring along the horizontal axis: <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_18.png" src="../_images/Equivariant_80_18.png" /></span> is actually the same as rotating twice and then mirroring along the vertical. In fact, you only need to have mirroing along one axis. We’ll choose the vertical axis by convention and denote that as <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>We can build the group action piece by piece. The group action for rotation can be represented as a 2D rotation matrix acting a point <span class="math notranslate nohighlight">\((x, y)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{k2\pi}{4} &amp; -\sin\frac{k2\pi}{4}\\
\sin\frac{k2\pi}{4} &amp; \cos\frac{k2\pi}{4}\\
\end{array}\right]
\left[\begin{array}{c}
x\\
y\\
\end{array}\right]
,\, k \in \left\{0, 1, 2, 3\right\}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> can allow us to do two rotations at once (<span class="math notranslate nohighlight">\(k = 2\)</span>) or the identity (<span class="math notranslate nohighlight">\(k = 0\)</span>). The vertical axis mirror action can be represented by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
1 &amp; 0\\
0 &amp; -1\\
\end{array}\right]
\left[\begin{array}{c}
x\\
y\\
\end{array}\right]
\end{split}\]</div>
<p>These two group actions can be ordered to correctly represent rotation then mirroring or vice-versa.</p>
<p>Now is this closed with the group elements <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, s\}\)</span>? Visually we have  <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_12.png" src="../_images/Equivariant_80_12.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_16.png" src="../_images/Equivariant_80_16.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_20.png" src="../_images/Equivariant_80_20.png" /></span>, <span class="pasted-inline"><img alt="../_images/Equivariant_80_10.png" src="../_images/Equivariant_80_10.png" /></span>? No. Consider <span class="math notranslate nohighlight">\(r^2\cdot{}s\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_10.png" src="../_images/Equivariant_80_10.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_18.png" src="../_images/Equivariant_80_18.png" /></span> which is not an element. To close the group, we need <span class="math notranslate nohighlight">\(\{e, r, r^2, r^3, s, rs, r^2s, r^3s\}\)</span>. The multiplication table (which defines the elements too) is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l|cccccccr}
&amp; e &amp; r &amp; r^2 &amp; r^3 &amp; s &amp; rs &amp; r^2s &amp; r^3s\\
\hline
e &amp; e &amp; r &amp; r^2 &amp; r^3 &amp; s &amp; rs &amp; rs^2 &amp; rs^3\\
r &amp; r &amp; r^2 &amp; r^3 &amp; e &amp; rs &amp; r^2s &amp; r^3s &amp; s\\
r^2 &amp; r^2 &amp; r^3 &amp; e &amp; r &amp; r^2s &amp; r^3s &amp; s &amp; rs\\
r^3 &amp; r^3 &amp; e &amp; r &amp; r^2 &amp; r^3s &amp; s &amp; rs &amp; r^2s\\
s &amp; s &amp; r^3s &amp; r^2s &amp; rs &amp; e &amp; r^3 &amp; r^2 &amp; r\\
rs &amp; rs &amp; s &amp; r^3s &amp; r^2s &amp; r &amp; e &amp; r^3 &amp; r^2\\
r^2s &amp; r^2s &amp; rs &amp; s &amp; r^3s &amp; r^2 &amp; r &amp; e &amp; r^3\\
r^3s &amp; r^3s &amp; r^2s &amp; rs &amp; s &amp; r^3 &amp; r^2 &amp; r &amp; e\\
\end{array}
\end{split}\]</div>
<p>This is a <a class="reference external" href="https://en.wikipedia.org/wiki/Cayley_table"><strong>Cayley table</strong></a>. Remember <em>The row factor comes first and the column factor second</em>. So <span class="math notranslate nohighlight">\(rs\cdot{}r^3\)</span> means we look at row <span class="math notranslate nohighlight">\(rs\)</span> and column <span class="math notranslate nohighlight">\(r^3\)</span> to get the group element, which in this case is <span class="math notranslate nohighlight">\(r^2s\)</span>.</p>
<p>As you can see from the Cayley table, the group is closed. Remember, elements like <span class="math notranslate nohighlight">\(rs\)</span> are not a binary operation. They are group elements, hence the missing binary operation symbol. We also see that the group is not commutative. <span class="math notranslate nohighlight">\(r\cdot{}s\)</span> is <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_10.png" src="../_images/Equivariant_80_10.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_22.png" src="../_images/Equivariant_80_22.png" /></span>, so <span class="math notranslate nohighlight">\(r\cdot{}s = rs\)</span> as expected. However, <span class="math notranslate nohighlight">\(s\cdot{}r\)</span> is <span class="pasted-inline"><img alt="../_images/Equivariant_80_8.png" src="../_images/Equivariant_80_8.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_12.png" src="../_images/Equivariant_80_12.png" /></span> <span class="math notranslate nohighlight">\(\rightarrow\)</span> <span class="pasted-inline"><img alt="../_images/Equivariant_80_14.png" src="../_images/Equivariant_80_14.png" /></span>, which is the group element <span class="math notranslate nohighlight">\(r^3s\)</span>.</p>
<p>We can also read the inverses off the table. For example, the inverse of <span class="math notranslate nohighlight">\(r\)</span> is the column which gives the identity element: <span class="math notranslate nohighlight">\(r^3\)</span>. This group is known as the dihedral group 4 <span class="math notranslate nohighlight">\(D_4\)</span>. It has order 8.</p>
<p>Now consider the translation group elements. For simplicity, let’s only consider integer translations. We can label them as <span class="math notranslate nohighlight">\(t_{w,h}\)</span>. So <span class="math notranslate nohighlight">\(t_{3,4}\)</span> means translate by <span class="math notranslate nohighlight">\(x + 3\)</span> and <span class="math notranslate nohighlight">\(y + 4\)</span>. Is this a proper group? Certainly it associative, there is an identity <span class="math notranslate nohighlight">\(t_{0,0}\)</span> and an inverse for each element <span class="math notranslate nohighlight">\(t_{-x, -y}\)</span>. What about closure? Yes, since translating twice is equivalent to one larger translation: <span class="math notranslate nohighlight">\(t_{w,h}\cdot{}t_{w', h'} = t_{w + w', h + h'}\)</span>. This expression also shows group action for translation.</p>
<p>What about when we combine with our other elements from the <span class="math notranslate nohighlight">\(D_4\)</span> group? Consider the product <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>. This means translating by <span class="math notranslate nohighlight">\((3,4)\)</span> and then rotating by 90° about the origin. If you consider this acting on a single point <span class="math notranslate nohighlight">\((0,0)\)</span>, you could get <span class="math notranslate nohighlight">\((0,0) \rightarrow (3,4) \rightarrow (-3,4)\)</span>. What element of our group would this represent? At first it seems like it could be <span class="math notranslate nohighlight">\(t_{-3,4}\)</span>. However, <span class="math notranslate nohighlight">\(t_{-3,4}\)</span> would only work specifically for starting at <span class="math notranslate nohighlight">\((0,0)\)</span>. If you started at <span class="math notranslate nohighlight">\((1,1)\)</span>, you would get to <span class="math notranslate nohighlight">\((-4,5)\)</span> with <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span> and <span class="math notranslate nohighlight">\((-2,5)\)</span> with <span class="math notranslate nohighlight">\(t_{-3,4}\)</span>. To be correct for <em>any point</em>, we need a different group element. So the product <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span> actually cannot be a product but instead must be a group element. In fact, our new combined group is just going to be <span class="math notranslate nohighlight">\(ab\)</span> where <span class="math notranslate nohighlight">\(a\)</span> is an element from <span class="math notranslate nohighlight">\(D_4\)</span> and <span class="math notranslate nohighlight">\(b\)</span> is a translation. Thus <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4} = rt_{3,4}\)</span>.</p>
<p>Combing these two groups, the translation and <span class="math notranslate nohighlight">\(D_4\)</span>, is an example of a <strong>semidirect product</strong>. A semidirect product just means that we create a new group by combining all possible group elements. There is some machinery for this, like the identity element in our new group is something like <span class="math notranslate nohighlight">\(et_{0,0}\)</span>, and it has some other structure. It is called semidirect, instead of direct, because we can actually mix our group elements. The elements both act on points in the same space (<span class="math notranslate nohighlight">\(x,y\)</span> plane), so this makes sense. Another condition is that we can only have a semidirect product when one subgroup is normal and the translation subgroup is the normal subgroup. It is coincidentally abelian, but these two properties are not always identical. This semidirect product group is called p4m.</p>
<p>Below, is an optional section that formalizes the idea of combining these two groups into one larger group.</p>
<div class="admonition-normal-subgroup admonition">
<p class="admonition-title">Normal Subgroup</p>
<p>A normal subgroup is a group of elements <span class="math notranslate nohighlight">\(n\)</span> from the group <span class="math notranslate nohighlight">\(G\)</span> called <span class="math notranslate nohighlight">\(N\)</span>. Each <span class="math notranslate nohighlight">\(n \in N\)</span> should have the property that <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1}\)</span> gives an element in <span class="math notranslate nohighlight">\(N\)</span> for any <span class="math notranslate nohighlight">\(g\)</span>.</p>
</div>
<p>This does not mean <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1} = n\)</span>, but instead that <span class="math notranslate nohighlight">\(g\cdot{}n\cdot{}g^{-1} = n'\)</span> where <span class="math notranslate nohighlight">\(n'\)</span> is some other element in <span class="math notranslate nohighlight">\(N\)</span>. For example, in p4m the translations form a normal subgroup. Rotating, translating, then doing the inverse of the rotation is equivalent to some translation. Notice that <span class="math notranslate nohighlight">\(D_4\)</span> is not a normal subgroup of p4m. If you do an inverse translation, rotate, then do a translation you may not have something equivalent to a rotation. It may be strange that we’re talking about the group p4m when we haven’t yet described how it’s defined (identity, inverse, binary op). We’ll do that with the semidirect product and then we could go back and verify that the translations are a normal subgroup more rigorously. I do not know the exact connection, but it seems that normal subgroups are typically abelian.</p>
<div class="admonition-semidirect-product admonition">
<p class="admonition-title">Semidirect Product</p>
<p>Given a normal subgroup of <span class="math notranslate nohighlight">\(G\)</span> called <span class="math notranslate nohighlight">\(N\)</span> and a subgroup <span class="math notranslate nohighlight">\(H\)</span>, we can define <span class="math notranslate nohighlight">\(G\)</span> using the semidirect product. Each element in <span class="math notranslate nohighlight">\(G\)</span> is a tuple of two elements in <span class="math notranslate nohighlight">\(N, H\)</span> written as <span class="math notranslate nohighlight">\((n, h)\)</span>. The identity is <span class="math notranslate nohighlight">\((e_n, e_h)\)</span> and the binary operation is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0be0841d-0fad-478c-8407-8910a1372e81">
<span class="eqno">(13.2)<a class="headerlink" href="#equation-0be0841d-0fad-478c-8407-8910a1372e81" title="Permalink to this equation">¶</a></span>\[\begin{equation}
(n_1, h_1) \cdot (n_2, h_2) = (n_1\cdot\phi(h_1)(n_1), h_1\cdot{}h_2)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span> is the conjugation of <span class="math notranslate nohighlight">\(n\)</span> <span class="math notranslate nohighlight">\(\phi(h)(n) = h\cdot{}n\cdot{}h^{-1}\)</span>. When a transform <span class="math notranslate nohighlight">\((n,h)\)</span> is applied, we follow the normal convention that <span class="math notranslate nohighlight">\(h\)</span> is applied first followed by <span class="math notranslate nohighlight">\(n\)</span>.</p>
</div>
<p>We are technically doing an outter semidirect product: combining them under the assumption that both <span class="math notranslate nohighlight">\(D_4\)</span> and <span class="math notranslate nohighlight">\(T\)</span> are part of a larger group which contains both. This is a bit of a semantic detail, but they are actually both part of <span class="math notranslate nohighlight">\(p4m\)</span> and a larger group called the affine group which includes translation, rotation, shear, translation, mirror, and scale operations on points. You could also argue they are part of groups which can be represented by 3x3 invertible matrices. Thus, you can combine these and get something that is still smaller than their larger containing group (<span class="math notranslate nohighlight">\(p4m\)</span> is smaller than all affine transformations).</p>
<p>One consequence of the semidirect product is that if you have a group element <span class="math notranslate nohighlight">\((n,h)\)</span> but want to instead apply <span class="math notranslate nohighlight">\(n\)</span> first (instead of <span class="math notranslate nohighlight">\(h\)</span>), you can use the binary operation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-be97792a-12f9-4199-869b-c5dbda48bab0">
<span class="eqno">(13.3)<a class="headerlink" href="#equation-be97792a-12f9-4199-869b-c5dbda48bab0" title="Permalink to this equation">¶</a></span>\[\begin{equation}
(e_n, h) \cdot (n, e_h) = (e_n\cdot\phi(h)(n), h\cdot{}e_h) = (\phi(h)(n), h)
\end{equation}\]</div>
<p>so <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span> somehow captures the effect of switching the order applying elements from <span class="math notranslate nohighlight">\(H\)</span> and <span class="math notranslate nohighlight">\(N\)</span>. In our case, this means swapping the order of rotation/mirroring and translation.</p>
<p>To show what effect the semidirect product has in p4m, we can clean-up our example above about <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>. We should write the first element of this binary product <span class="math notranslate nohighlight">\(r\)</span> as a tuple of group elements: one from the <span class="math notranslate nohighlight">\(D_4\)</span> and one from the translations. Since there is no translation for <span class="math notranslate nohighlight">\(r\)</span>, we use the identity. Thus we write <span class="math notranslate nohighlight">\(r\)</span> as <span class="math notranslate nohighlight">\((t_{0,0}, r)\)</span> in our semidirect product group p4m. Note that the normal subgroup comes first (applied last) by convention. Similarly, <span class="math notranslate nohighlight">\(t_{3,4}\)</span> is written as <span class="math notranslate nohighlight">\((t_{3,4}, e)\)</span>. Our equation becomes:</p>
<div class="math notranslate nohighlight">
\[
(t_{0,0}, r)\cdot(t_{3,4}, e) = (t_{0,0}\cdot\phi(r)(t_{3,4}), r\cdot{}e) = (t_{0,0}\cdot\phi(r)(t_{3,4}), r)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi\)</span> is the automorphism that distinguishes a semidirect product from a direct product. The direct product has <span class="math notranslate nohighlight">\(\phi(h)(n) = n\)</span> so that the binary operation for the direct product group is just the element-wise binary products. <span class="math notranslate nohighlight">\(\phi(h)(n) = hnh^{-1}\)</span> for semidirect products. In our equation, this means <span class="math notranslate nohighlight">\(\phi(r)(t_{3,4}) = r\cdot{}t_{3,4}\cdot{}r^3\)</span>. Substituting this and using the fact that both groups have the same binary operation (matrix multiplication, as we’ll see shortly):</p>
<div class="math notranslate nohighlight">
\[
(t_{3,4}\phi(r)(t_{3,4}), r) = (r\cdot{}t_{3,4}\cdot{}r^3, r) = r\cdot{}t_{3,4}\cdot{}r^3\cdot r = r\cdot{}t_{3,4}
\]</div>
<p>Thus we’ve proved that translating by <span class="math notranslate nohighlight">\(3,4\)</span> followed by rotating can be expressed as <span class="math notranslate nohighlight">\(r\cdot{}t_{3,4}\)</span>, which seems like a lot of work for an obvious result. I won’t cover the semidirect product of the group action, but we’ll see that we do not necessarily need to build a group action encapsulating both translation and rotation/mirroring.</p>
</div>
<div class="section" id="so-3-lie-group">
<h3><span class="section-number">13.3.3. </span>⚽ SO(3) Lie Group<a class="headerlink" href="#so-3-lie-group" title="Permalink to this headline">¶</a></h3>
<p>SO(3) is the group for analyzing 3D point clouds like trajectories or crystal structures (with no other symmetries). SO(3) is the group of all rotations about the origin in 3D. The group is non-abelian because rotations in 3D are not commutative. The group order is infinite, because you can rotate in this group by any angle (or sets of angles). If you are interested in allowing translations, you can use SE(3) which is the semidirect product of SO(3) and the translation group (like p4m), which is a normal subgroup.</p>
<p>The SO(3) name is a bit strange. SO stands for “special orthogonal” which are two properties of square matrices. In this case, the matrices are <span class="math notranslate nohighlight">\(3\times3\)</span>. Orthogonal  means the columns sum to one and special means the determinant is 1. Interestingly, all rotations in 3D around the origin are also the SO(3) matrices.</p>
<p>One detail is that since we’re rotating (no scale or translation) <em>our points will all be on a sphere</em>. We cannot move the radius. By convention then we’ll have a radius 1. The group action is the product of 3 3D rotation matrices <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> where <span class="math notranslate nohighlight">\(\alpha,\gamma \in [0, 2\pi], \beta \in [0, \pi]\)</span> and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
R_z(\theta) = \left[\begin{array}{lcr}
\cos\theta &amp; -\sin\theta &amp; 0\\
\sin\theta &amp; \cos\theta &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
R_y(\theta) = \left[\begin{array}{lcr}
\cos\theta &amp; 0 &amp; \sin\theta \\
0 &amp; 1 &amp; 0\\
-\sin\theta &amp;  0 &amp; \cos\theta\\
\end{array}\right]
\end{split}\]</div>
</div>
<div class="section" id="groups-on-spaces">
<h3><span class="section-number">13.3.4. </span>Groups on Spaces<a class="headerlink" href="#groups-on-spaces" title="Permalink to this headline">¶</a></h3>
<p>We’ve defined transforms and their relationships to one another via group theory. Now we need to actually connect the transforms to a space. It is helpful to think about the space as Euclidean with a concept of distance and coordinates, but we’ll see that this is not required. Our space could be vertices on a graph or integers or classes. There are <em>some</em> requirements though. The first is that our space must be <strong>homogeneous</strong>. Homogeneous means that from any point in our space <span class="math notranslate nohighlight">\(x\)</span> we can reach any other point with a transform <span class="math notranslate nohighlight">\(g\)</span> from our group <span class="math notranslate nohighlight">\(G\)</span>. The second requirement is that if our group is infinite, the space must <strong>locally compact</strong>. This is a concept from topology and we won’t really ever be troubled by it. Most spaces we’ll see in chemistry or materials science (Euclidean spaces) are locally compact. This doesn’t matter for finite groups, so we can use non-compact spaces. If the group transforms are further smooth and have smooth inverses, the group (and associated space) are called a <strong>lie group</strong>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>The lie group definition is a side-note, it has nothing to do with our analysis.</p>
</div>
<div class="tabbed-set docutils">
<input checked="checked" id="c9657361-f441-4831-9c3d-3b05a92eb993" name="d3228082-92a8-42fa-80d0-5dd5cf685650" type="radio">
</input><label class="tabbed-label" for="c9657361-f441-4831-9c3d-3b05a92eb993">
⬡ Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>The space is homogeneous because our group includes “compound” rotations like <span class="math notranslate nohighlight">\(r^4\)</span>. This is a finite group, so we do not require the space to be compact.</p>
</div>
<input id="78463559-66e8-4a7f-b47f-cc4e99cc1d2a" name="d3228082-92a8-42fa-80d0-5dd5cf685650" type="radio">
</input><label class="tabbed-label" for="78463559-66e8-4a7f-b47f-cc4e99cc1d2a">
▩ Locally Compact p4m</label><div class="tabbed-content docutils">
<p>The space is homogeneous since we can use a translation to get to any other point. The space is locally compact because we are in 2D Euclidean geometry. It is not a lie group, because the dihedral operations (rotate/mirror) are not smooth. Or at least I don’t think so; I don’t know enough about topology.</p>
</div>
<input id="356cda89-2c5e-44f3-a17d-35c771f01505" name="d3228082-92a8-42fa-80d0-5dd5cf685650" type="radio">
</input><label class="tabbed-label" for="356cda89-2c5e-44f3-a17d-35c771f01505">
⚽ SO(3) Lie Group</label><div class="tabbed-content docutils">
<p>The space is homogeneous because we restrict ourselves to being on the sphere. The space is locally compact because we are in 3D Euclidean geometry. This is a lie group because the transformations are continuous and smooth.</p>
</div>
</div>
<p>The requirement of space being homogeneous is fairly strict. It means we cannot work with <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> with a finite group like mirror and fixed rotations (i.e., p4m without translations). For example, going from <span class="math notranslate nohighlight">\(x = (0,0)\)</span> to <span class="math notranslate nohighlight">\(x = (1,1)\)</span> cannot be done with rotations/mirror group elements alone. As you can see, working in a Euclidean space thus requires a locally compcat group. Similarily, a finite group implies a finite space because of the homogeneous requirement.</p>
<p>This may seem like a ton of work. We could have just started with <span class="math notranslate nohighlight">\(xyz\)</span> coordinates and rotation matrices. Please continue to wait though, we’re about to see something incredible.</p>
</div>
</div>
<div class="section" id="equivariance-definition">
<h2><span class="section-number">13.4. </span>Equivariance Definition<a class="headerlink" href="#equivariance-definition" title="Permalink to this headline">¶</a></h2>
<p>You should be thinking now about how we can define equivariance using our new groups. That’s where we’re headed. We need to do a bit of work now to “lift” neural networks and our features into the framework we’re building. First, in <a class="reference internal" href="data.html"><span class="doc">Input Data &amp; Equivariances</span></a> we defined our features as being composed of tuples <span class="math notranslate nohighlight">\((\vec{r}_i, \vec{x}_i)\)</span> where <span class="math notranslate nohighlight">\(\vec{r}_i\)</span> is a spatial point and <span class="math notranslate nohighlight">\(\vec{x}_i\)</span> are the features at that point. Let’s now view these input data as functions, defined as <span class="math notranslate nohighlight">\(f(\vec{r}) = \vec{x}\)</span> and assume if a point <span class="math notranslate nohighlight">\(\vec{r}'\)</span> isn’t in our training data then <span class="math notranslate nohighlight">\(f(\vec{r}') = \vec{0}\)</span>. More formally, our training data is a function <span class="math notranslate nohighlight">\(f:\mathcal{X} \rightarrow \mathbb{R}^n\)</span> that maps from our homogeneous space <span class="math notranslate nohighlight">\(\mathcal{x}\)</span> to real vector (or complex vectors) of dimension <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>We have promoted our data into a function and now a neural network can no longer be just function since its input is a function. Our neural network will be also promoted to an <strong>linear map</strong>, which has an input of a function and an output of a function. Formally, our network <span class="math notranslate nohighlight">\(\psi: f(\mathcal{X}) \rightarrow f'(\mathcal{X})\)</span>. Notice the input and output spaces of the functions should be the same (we cannot switch from 2D to 3D). Linear maps are also called <strong>operators</strong>, depending on which branch of mathematics you’re in.</p>
<p>The last piece of equivariance is to promote our group elements, which transform points, to work on functions.</p>
<div class="admonition-g-function-transform-definition admonition">
<p class="admonition-title">G-Function Transform Definition</p>
<p>An element <span class="math notranslate nohighlight">\(g\)</span> of group <span class="math notranslate nohighlight">\(G\)</span> on the homogeneous space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> can act on a function <span class="math notranslate nohighlight">\(f:\mathcal{X}\rightarrow \mathbb{R}^n\)</span> via the group transform linear map <span class="math notranslate nohighlight">\(\mathbb{T}_g: f(\mathcal{X}) \rightarrow f'(\mathcal{X})\)</span> defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-94d2db38-d350-4db2-9059-fcec56bb43e1">
<span class="eqno">(13.4)<a class="headerlink" href="#equation-94d2db38-d350-4db2-9059-fcec56bb43e1" title="Permalink to this equation">¶</a></span>\[\begin{equation}
f'(gx) = f(x) \Rightarrow f'(x) = f(g^{-1}x)
\end{equation}\]</div>
</div>
<p>This definition takes a moment to think about. Consider a translation of an image. You want to move an image to the left by 10 pixels, so <span class="math notranslate nohighlight">\(g = t_{10,0}\)</span>. The image is defined by the function <span class="math notranslate nohighlight">\(f(x,y) = (r, g, b)\)</span>, where <span class="math notranslate nohighlight">\(r,g,b\)</span> is the color. We want <span class="math notranslate nohighlight">\(T_g f(x, y)\)</span>. Without knowing about groups, you can intuit that translating can be done by creating a new function <span class="math notranslate nohighlight">\(f'(x', y') = f(x - 10, y)\)</span>. Notice that the inverse of <span class="math notranslate nohighlight">\(g^{-1} = t_{-10, 0}\)</span> acts on the points, not <span class="math notranslate nohighlight">\(g\)</span>. Recall that a group requires there to be an inverse for any group element.</p>
<p>Now we have all the pieces to define an equivariant neural network:</p>
<div class="admonition-equivariant-neural-network-definition admonition">
<p class="admonition-title">Equivariant Neural Network Definition</p>
<p>Given a group <span class="math notranslate nohighlight">\(G\)</span> that has actions on two homogeneous space <span class="math notranslate nohighlight">\(\mathcal{X_1}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{X_2}\)</span>, a G-equivariant neural network is a linear map <span class="math notranslate nohighlight">\(\psi: f(\mathcal{X_1}) \rightarrow f'(\mathcal{X_2})\)</span> that has the property<span id="id7">[<a class="reference internal" href="#id100">KT18</a>]</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6273cbe1-e7a1-46ba-bffc-51280879f5c0">
<span class="eqno">(13.5)<a class="headerlink" href="#equation-6273cbe1-e7a1-46ba-bffc-51280879f5c0" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\psi\left[\mathbb{T}_g f(x)\right] = \mathbb{T'}_{g}\psi\left[f(x)\right]\;\forall\, f(x)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{T}_g\)</span> and <span class="math notranslate nohighlight">\(\mathbb{T}'_g\)</span> are G-function transforms on the two spaces. If <span class="math notranslate nohighlight">\(\mathbb{T}'_g = \textrm{id}\)</span>, meaning the transform is the identity in the output space regardless of <span class="math notranslate nohighlight">\(g\)</span>, then <span class="math notranslate nohighlight">\(\psi\)</span> is a G-invariant neural network.</p>
</div>
<p>The definition means that we get the same output if we transform the input function to the neural network or transform the output (in the equivariant case). In a specific example, if we rotate the input by 90 degrees, that’s the same result as rotating the output by 90 degrees. Take a moment to ensure that matches your idea of what equivariance means. After all this math, we’ve generalized equivariance to arbitrary spaces and groups.</p>
<p>What the two input and output spaces? It’s easiest to think about them as the same space for equivariant neural networks. For an invariant, the output space is typically a scalar. Another example for an invariant one could be aligning a molecular structure to a reference. The neural network should align to the same reference regardless of how the input is transformed.</p>
</div>
<div class="section" id="g-equivariant-convolution-layers">
<h2><span class="section-number">13.5. </span>G-Equivariant Convolution Layers<a class="headerlink" href="#g-equivariant-convolution-layers" title="Permalink to this headline">¶</a></h2>
<p>Kondor and Trivedi showed that there is <em>only one</em> way to make a G-equivariant neural network:</p>
<div class="admonition-g-equivariant-convolution-theorem admonition">
<p class="admonition-title">G-Equivariant Convolution Theorem</p>
<p>A neural network layer (linear map) <span class="math notranslate nohighlight">\(\psi\)</span> is G-equivariant if and only if its form is a convolution operator <span class="math notranslate nohighlight">\(*\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-a628e97d-e9b8-4219-8fa2-008d2b533bd7">
<span class="eqno">(13.6)<a class="headerlink" href="#equation-a628e97d-e9b8-4219-8fa2-008d2b533bd7" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\label{discconv}
\psi(f) = (f * \phi)(u) = \sum_{g \in G} f\uparrow^G\left(ug^{-1}\right)\phi\uparrow^G\left(g\right)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(f: H \rightarrow \mathbb{R}^n\)</span> and <span class="math notranslate nohighlight">\(\phi: H' \rightarrow \mathbb{R}^n\)</span> are functions of quotient spaces <span class="math notranslate nohighlight">\(H\)</span> and <span class="math notranslate nohighlight">\(H'\)</span>. If the group <span class="math notranslate nohighlight">\(G\)</span> is locally compact (infinite elements), then the convolution operator is</p>
<div class="amsmath math notranslate nohighlight" id="equation-7aca766d-e4e3-45e8-99b2-bf34087d0fc5">
<span class="eqno">(13.7)<a class="headerlink" href="#equation-7aca766d-e4e3-45e8-99b2-bf34087d0fc5" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\label{cont-conv}
\psi(f) = (f * \phi)(u) = \int_G f\uparrow^G\left(ug^{-1}\right)\phi\uparrow^G\left(g\right)\,d\mu(g)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> is the group Haar measure. A <a class="reference external" href="https://en.wikipedia.org/wiki/Haar_measure">Haar measure</a> is a generalization of the familiar integrand factor you see when doing integrals in polar coordinates or spherical coordinates.</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>This is one of the strongest theorems in deep learning. It says there is only one way to achieve equivariance in a neural network. This may seem counter-intuitive since there are many competing approaches to convolutions. These other approaches are actually equivalent to a convolution, just it can be hard to notice.</p>
</div>
<p>As you can see from the theorem, we must introduces more new concepts. The first important detail is that all our functions are over our group elements (technically the quotient space <span class="math notranslate nohighlight">\(G / H_0\)</span>), not our space. This should seem strange. We will easily fix this because there is a (bijective) way to assign one group element to each point in the space. The second detail is the <span class="math notranslate nohighlight">\(f \uparrow^G\)</span>. The order of the group <span class="math notranslate nohighlight">\(G\)</span> is greater than or equal to the number of points in our space, so if the function is defined on our space, we must “lift” it up to the group <span class="math notranslate nohighlight">\(G\)</span> which has more elements. The last detail is the point about <strong>quotient spaces</strong>. Quotient spaces are how we cut-up our group <span class="math notranslate nohighlight">\(G\)</span> into subgroups so that one has the same order as the number of points in our space. Below I detail these new concepts just enough so that we can implement and understand these convolutions.</p>
</div>
<div class="section" id="converting-between-space-and-group">
<h2><span class="section-number">13.6. </span>Converting between Space and Group<a class="headerlink" href="#converting-between-space-and-group" title="Permalink to this headline">¶</a></h2>
<p>Let’s see how we can convert between functions on the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and functions on the group <span class="math notranslate nohighlight">\(G\)</span>. <span class="math notranslate nohighlight">\(|G| \geq |\mathcal{X}|\)</span> (because the space is homogeneous) so it is rare that we can uniquely replace each point in space with a group in <span class="math notranslate nohighlight">\(G\)</span>. Instead, we will construct a partitioning of <span class="math notranslate nohighlight">\(G\)</span> into <span class="math notranslate nohighlight">\(|\mathcal{X}|\)</span> sets called a quotient space <span class="math notranslate nohighlight">\(G / H\)</span> such that <span class="math notranslate nohighlight">\(|G / H| = |\mathcal{X}|\)</span>. It turns out, there is a well-studied approach to arranging elements in a group called <strong>cosets</strong>. Constructing cosets is a two-step process. First we define a subgroup <span class="math notranslate nohighlight">\(H\)</span>. A <strong>subgroup</strong> means it is itself a group; it has identities and inverses. We cannot accidentally leave <span class="math notranslate nohighlight">\(H\)</span>, <span class="math notranslate nohighlight">\(h_1\cdot{} h_2 \in H\)</span>. For example, translation transformations are a subgroup because you cannot accidentally create a rotation when combining two translations.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>This process of constructing cosets and then using that to lift our function is closely related to the process of finding an induced representation on <span class="math notranslate nohighlight">\(G\)</span> via a representation on <span class="math notranslate nohighlight">\(H\)</span>.</p>
</div>
<p>After constructing a subgroup <span class="math notranslate nohighlight">\(H\)</span>, we can apply an element <span class="math notranslate nohighlight">\(g\)</span> to every element in <span class="math notranslate nohighlight">\(H\)</span>, written as</p>
<div class="amsmath math notranslate nohighlight" id="equation-9aaa956a-b6dd-4291-8cc3-24191739da68">
<span class="eqno">(13.8)<a class="headerlink" href="#equation-9aaa956a-b6dd-4291-8cc3-24191739da68" title="Permalink to this equation">¶</a></span>\[\begin{equation}
gH = \left\{g \cdot h \forall h \in H\right\}
\end{equation}\]</div>
<p>If this sounds strange, wait for an example. <span class="math notranslate nohighlight">\(gH\)</span> is called a <strong>left coset</strong>. We mention the direction because <span class="math notranslate nohighlight">\(G\)</span>’s binary operation may not be commutative (non-abelian). What happens if <span class="math notranslate nohighlight">\(g\)</span> is in <span class="math notranslate nohighlight">\(H\)</span>? No problem; <span class="math notranslate nohighlight">\(H\)</span> is a group so applying an element to every element in <span class="math notranslate nohighlight">\(H\)</span> just gives back <span class="math notranslate nohighlight">\(H\)</span> (i.e. <span class="math notranslate nohighlight">\(hH = H\)</span>). Cosets are not groups, they are definitely not closed or have inverses. What’s the point of making all these cosets? Remember our goal is to partition <span class="math notranslate nohighlight">\(G\)</span> into a bunch of smaller sets so that we have one for each point in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. Constructing cosets partitions <span class="math notranslate nohighlight">\(G\)</span> for sure, but do we get enough? Could we accidentally have overlaps between cosets, where <span class="math notranslate nohighlight">\(g_1H\)</span> and <span class="math notranslate nohighlight">\(g_2H\)</span> contain the same elements?</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>If your group involves rotations, make life easy on yourself and always choose <span class="math notranslate nohighlight">\(x_0\)</span> as the origin (or center of the rotations).</p>
</div>
<p>It turns out if our space is homogeneous we can construct our cosets in a special way so that we have exactly one coset for each point in the space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. To get our group, we pick an arbitrary point in the space <span class="math notranslate nohighlight">\(x_0\)</span>. Often this will be the origin. Then we choose our subgroup <span class="math notranslate nohighlight">\(H\)</span> to be all group elements that leave <span class="math notranslate nohighlight">\(x_0\)</span> unchanged.  This is called a stabilizer subgroup <span class="math notranslate nohighlight">\(H_0\)</span> and is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-f1355f10-878c-4260-8c99-20b1bdba60c3">
<span class="eqno">(13.9)<a class="headerlink" href="#equation-f1355f10-878c-4260-8c99-20b1bdba60c3" title="Permalink to this equation">¶</a></span>\[\begin{equation}
H_0 = \left\{ g \in G \,\textrm{such that}\, g x_0 = x_0\right\}
\end{equation}\]</div>
<p>We will not prove that this is a group itself. This defines our subgroup. Here’s the remarkable thing: we will have exactly enough cosets with this stabilizer as there are points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>. However, multiple <span class="math notranslate nohighlight">\(g's\)</span> will give the same coset (as expected, since <span class="math notranslate nohighlight">\(|G| &gt; |\mathcal{X}|\)</span>).</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>This set of all cosets is itself a group and it is written as <span class="math notranslate nohighlight">\(G / H_0\)</span>. The fact that the cosets is a group is just weird. What is the identity coset? How do you define binary operations on cosets? It turns out we do not need these items but it is fascinating.</p>
</div>
<p>Now comes the details, how do we match-up points in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to the cosets? We know that the space is homogeneous  so each point in <span class="math notranslate nohighlight">\(x\)</span> can be reached from our arbitrary origin by a group element <span class="math notranslate nohighlight">\(gx_0 = x\)</span>. That’s one way to connect points to group elements, but which coset will <span class="math notranslate nohighlight">\(g\)</span> be in? There also may be multiple <span class="math notranslate nohighlight">\(g\)</span>s that satisfy the equation. It turns out that all the group elements that satisfy the equation will be in the same coset. The reason why is that <span class="math notranslate nohighlight">\(g\cdot h x_0 = gx_0\)</span> because all elements <span class="math notranslate nohighlight">\(h\)</span> of the stabilizer group do not move <span class="math notranslate nohighlight">\(x_0\)</span>. Quite elegant.</p>
<p>How do we find which coset we need? Since the identity <span class="math notranslate nohighlight">\(e\)</span> is in <span class="math notranslate nohighlight">\(H_0\)</span> (by definition), the coset <span class="math notranslate nohighlight">\(gH_0\)</span> will contain <span class="math notranslate nohighlight">\(g\)</span> itself. Thus, we can convert a function <span class="math notranslate nohighlight">\(f(x)\)</span> from the space to be a function on the quotient space <span class="math notranslate nohighlight">\(f(g)\)</span> via what we call <strong>lifting</strong>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d5bc213c-486c-4786-afc0-e7f5901b76fe">
<span class="eqno">(13.10)<a class="headerlink" href="#equation-d5bc213c-486c-4786-afc0-e7f5901b76fe" title="Permalink to this equation">¶</a></span>\[\begin{equation}
f\uparrow^G(g) = f(gx_0)
\end{equation}\]</div>
<p>One point to note is that you can plug any element <span class="math notranslate nohighlight">\(g\)</span> from the group into <span class="math notranslate nohighlight">\(f\uparrow^G(g)\)</span> but it is bijective only over <span class="math notranslate nohighlight">\(G / H\)</span> (the cosets). Your null space will be the whole subgroup <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>A coset can have multiple labels in this system. <span class="math notranslate nohighlight">\(g_1H_0\)</span> and <span class="math notranslate nohighlight">\(g_2H_0\)</span> could be the same coset. There are no consequences of this, but just be aware.</p>
</div>
<p>Going the opposite, from a function on the group to the space, is called <strong>projecting</strong> because it will have a smaller domain. We can use the same process as above. We create the quotient space and then just take the average over a single coset to get a single value for the point <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1e028d01-3f84-4729-a2fd-d11f978adae1">
<span class="eqno">(13.11)<a class="headerlink" href="#equation-1e028d01-3f84-4729-a2fd-d11f978adae1" title="Permalink to this equation">¶</a></span>\[\begin{equation}
f\downarrow_\mathcal{X}(x) = \frac{1}{|H_0|}\sum_{u \in gH_0} f(u), \: gx_0 = x
\end{equation}\]</div>
<p>where we’ve used the fact that <span class="math notranslate nohighlight">\(|gH_0| = |H_0|\)</span>. Note that the coset generating element <span class="math notranslate nohighlight">\(g\)</span> is found by solving <span class="math notranslate nohighlight">\(gx_0 = x\)</span>, where of course <span class="math notranslate nohighlight">\(g\)</span> is not a stabilizing element (otherwise <span class="math notranslate nohighlight">\(gx_0 = x_0\)</span> by definition). Let’s see some examples now to make all of these easier to understand.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="31252513-7122-4425-8b63-3ebcbfd9beff" name="4274ca67-559f-4bfa-8063-417237d8577f" type="radio">
</input><label class="tabbed-label" for="31252513-7122-4425-8b63-3ebcbfd9beff">
⬡ Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>Our function is the color of the vertices in our picture <span class="pasted-inline"><img alt="../_images/Equivariant_80_0.png" src="../_images/Equivariant_80_0.png" /></span> <span class="math notranslate nohighlight">\(f(x) = (r, g, b)\)</span> where <span class="math notranslate nohighlight">\(r,g,b\)</span> are fractions of the color red, blue green. If we define the vertices to start at the line pointing up, we can label them <span class="math notranslate nohighlight">\(0,\ldots,5\)</span>. So for example <span class="math notranslate nohighlight">\(f(0) =(0.11, 0.74, 0.61)\)</span>, which is the color of the top vertex.</p>
<p>We can define the origin as <span class="math notranslate nohighlight">\(x_0 = 0\)</span>. <span class="math notranslate nohighlight">\(|G| = |\mathcal{X}|\)</span> for this finite group and thus our stabilizer subgroup only contains the identity <span class="math notranslate nohighlight">\(H_0 = \{e\}\)</span>. Our cosets and their associated points will be <span class="math notranslate nohighlight">\((eH_0, x = 0), (rH_0, x = 1), (r^2H_0, x = 2), (r^3H_0, x = 3), (r^4H_0, x = 4), (r^5H_0, x = 5)\)</span>. The lifted <span class="math notranslate nohighlight">\(f\uparrow^G(g)\)</span> can be easily defined using these cosets.</p>
</div>
<input id="0b9dc8b7-3404-4113-8e0b-c68fb038ff7e" name="4274ca67-559f-4bfa-8063-417237d8577f" type="radio">
</input><label class="tabbed-label" for="0b9dc8b7-3404-4113-8e0b-c68fb038ff7e">
▩ Locally Compact p4m</label><div class="tabbed-content docutils">
<p>p4m is intended for images, so our example will be a function <span class="math notranslate nohighlight">\(f: \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> that represents a color image. This group contains rotations about the origin, so if we choose the origin as our stabilizer it will cleanly separate our group. Namely:</p>
<div class="math notranslate nohighlight">
\[
H_0 = \left\{e_ne_r, e_nr, e_nr^2, e_nr^3 , e_ns , e_nrs , e_nr^2s , e_nr^3s\right\}
\]</div>
<p>where our elements have been written out as the semidirect product of translations and <span class="math notranslate nohighlight">\(D_4\)</span> as discussed previously. Let’s compute a coset to get a sense of this process. Consider the group element <span class="math notranslate nohighlight">\(t_{1,0}e_r\)</span> creating the coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span>. The first element of the coset is <span class="math notranslate nohighlight">\(t_{1,0}e_r \cdot e_ne_r = t_{1,0}e_r\)</span>. The second element is <span class="math notranslate nohighlight">\(t_{1,0}e_r \cdot t_{0,0}r = t_{1,0}r\)</span>. The rest of the elements of this coset are:</p>
<div class="math notranslate nohighlight">
\[
t_{1,0}e_rH_0 = \left\{t_{1,0}e_r , t_{1,0}r , t_{1,0}r^2 ,t_{1,0}r^3 , t_{1,0}s , t_{1,0}rs , t_{1,0}r^2s , t_{1,0}r^3s\right\}
\]</div>
<p>Note these were simple to compute because <span class="math notranslate nohighlight">\(\phi(g)(e_n) = ge_ng^{-1} = e_n\)</span>. Now what point is this associated with? Consider the first non-identity coset element <span class="math notranslate nohighlight">\(t_{1,0}r\)</span> acting on the origin: <span class="math notranslate nohighlight">\((0,0)\rightarrow(0,0)\rightarrow(1,0)\)</span>. You’ll see similarly that all elements in the coset will follow the same pattern: the first element from <span class="math notranslate nohighlight">\(H_0\)</span> doesn’t move the origin (by definition) and the second element is the same in the coset (translation by <span class="math notranslate nohighlight">\(x + 1\)</span>). Thus, the first coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span> is associated with the point <span class="math notranslate nohighlight">\((1,0)\)</span>.</p>
<p>Now consider a coset that involves a <span class="math notranslate nohighlight">\(D_4\)</span> element: <span class="math notranslate nohighlight">\(t_{1,0}rsH_0\)</span>. You can compute its elements as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
t_{1,0}rsH_0 = \left\{t_{1,0}rs, t_{1,0}s, t_{1,0}r^3s, t_{1,0}r^2s, t_{1,0}r, t_{1,0}e_r , t_{1,0}r^3 , t_{1,0}r^2\\\right\}
\end{split}\]</div>
<p>This contains all the same elements as the coset <span class="math notranslate nohighlight">\(t_{1,0}e_rH_0\)</span>! This is because we have more group elements than space in <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>; multiple <span class="math notranslate nohighlight">\(g\)</span>’s result in the same coset. This doesn’t change our intuition though: the translation transform still defines the connection between our coset and the space. Our lifting function will be</p>
<div class="math notranslate nohighlight">
\[
f\uparrow^G(g) = f\uparrow^G\left((t_{x,y}, h)\right) = f(x,y)
\]</div>
</div>
<input id="584e4c18-4bc7-400a-b14e-d05c441cc2a6" name="4274ca67-559f-4bfa-8063-417237d8577f" type="radio">
</input><label class="tabbed-label" for="584e4c18-4bc7-400a-b14e-d05c441cc2a6">
⚽ SO(3) Lie Group</label><div class="tabbed-content docutils">
<p>For this example, our function will be points on the sphere <span class="math notranslate nohighlight">\(f(x) = \sum_i \delta(x - x_i)\)</span>. We can represent the group element rotations (among other choices) as being the product of three rotations about the <span class="math notranslate nohighlight">\(y\)</span> and <span class="math notranslate nohighlight">\(z\)</span> axes: <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> If that seems surprising, remember that rotations are not commutative. Santa lives in the north pole, so let’s choose the north pole <span class="math notranslate nohighlight">\((0, 0, 1)\)</span> as our stabilizer. You cannot choose <span class="math notranslate nohighlight">\((0,0,0)\)</span> remember because it is not in the space. Our subgroup is rotations that only involve <span class="math notranslate nohighlight">\(\gamma\)</span>, for example <span class="math notranslate nohighlight">\(R_z(0)R_y(0)R_z(90)\)</span> is in our subgroup <span class="math notranslate nohighlight">\(H_0\)</span>. Let’s generate a coset, say for the group element <span class="math notranslate nohighlight">\(g = R_z(120)R_y(0)R_z(60)\)</span>. The coset <span class="math notranslate nohighlight">\(gH_0\)</span> will be rotations of <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60)R_z(0)R_y(0)R_z(\gamma)\)</span>, which can be simplified to <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60 + \gamma)\)</span>. Thus the coset is <span class="math notranslate nohighlight">\(gH_0 = \left\{R_z(120)R_y(0)R_z(60 + \gamma)\, \forall \gamma \in [0, 2\pi]\right\}\)</span></p>
<p>Now what point is associated with this coset? It will be this rotation applied to the origin: <span class="math notranslate nohighlight">\(R_z(120)R_y(0)R_z(60 + \gamma)x_0\)</span>. The first rotation has no effect, by definition, so it becomes <span class="math notranslate nohighlight">\(R_z(120)R_y(0)x_0\)</span>. The general form is that the coset for a point <span class="math notranslate nohighlight">\(x\)</span> is the rotation such that <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)x_0 = x\)</span>. This quotient space happens to be identical to SO(2), rotations in 2D, because it’s defined by two angles. The lifting functions is defined as:</p>
<div class="math notranslate nohighlight">
\[
f\uparrow^G(g) = f\uparrow^G\left(R_z(\alpha)R_y(\beta)R_z(\gamma)\right) = f\left(R_z(\alpha)R_y(\beta)x_0\right)
\]</div>
</div>
</div>
</div>
<div class="section" id="g-equivariant-convolutions-on-finite-groups">
<h2><span class="section-number">13.7. </span>G-Equivariant Convolutions on Finite Groups<a class="headerlink" href="#g-equivariant-convolutions-on-finite-groups" title="Permalink to this headline">¶</a></h2>
<p>We now have all the tools to build an equivariant network for a finite group. We’ll continue with our example group <span class="math notranslate nohighlight">\(Z_6\)</span> on vertices of a hexagon. The hidden cell below does our imports.</p>
<div class="cell tag_hidden-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">color_cycle</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;#1BBC9B&quot;</span><span class="p">,</span> <span class="s2">&quot;#F06060&quot;</span><span class="p">,</span> <span class="s2">&quot;#5C4B51&quot;</span><span class="p">,</span> <span class="s2">&quot;#F3B562&quot;</span><span class="p">,</span> <span class="s2">&quot;#6e1bc2&quot;</span><span class="p">,</span> <span class="s2">&quot;#AAAAAA&quot;</span><span class="p">]</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.prop_cycle&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">cycler</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">color_cycle</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s start by defining our input function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make our colors (nothing to do with the model)</span>

<span class="n">vertex_colors</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">color_cycle</span><span class="p">:</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">16</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">//</span> <span class="mi">256</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">-</span> <span class="n">r</span> <span class="o">*</span> <span class="mi">256</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">//</span> <span class="mi">256</span>
    <span class="n">hex_color</span> <span class="o">=</span> <span class="n">hex_color</span> <span class="o">-</span> <span class="n">g</span> <span class="o">*</span> <span class="mi">256</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">hex_color</span>
    <span class="n">vertex_colors</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">r</span> <span class="o">/</span> <span class="mi">256</span><span class="p">,</span> <span class="n">g</span> <span class="o">/</span> <span class="mi">256</span><span class="p">,</span> <span class="n">b</span> <span class="o">/</span> <span class="mi">256</span><span class="p">))</span>
<span class="n">vertex_colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vertex_colors</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">z6_fxn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">vertex_colors</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>


<span class="n">z6_fxn</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.10546875, 0.734375  , 0.60546875])
</pre></div>
</div>
</div>
</div>
<p>If we assume our group is indexed already by our vertex coordinates <span class="math notranslate nohighlight">\(\{0,\ldots, 5\}\)</span> then our function is already defined on the group. Now we need our trainable kernel function. It will be defined like our other function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make weights be 3x3 matrices at each group element</span>
<span class="c1"># 3x3 so that we have 3 color channels in and 3 out</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">z6_phi</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">weights</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>


<span class="n">z6_phi</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.18718385,  1.53277921,  1.46935877],
       [ 0.15494743,  0.37816252, -0.88778575],
       [-1.98079647, -0.34791215,  0.15634897]])
</pre></div>
</div>
</div>
</div>
<p>Now we can define our group convolution operator from Equation 8.6. We do need one helper function to get an inverse group element. Remember too that this returns a <em>function</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">6</span> <span class="o">-</span> <span class="n">g</span><span class="p">)</span> <span class="o">%</span> <span class="mi">6</span>


<span class="k">def</span> <span class="nf">z6_prod</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">g1</span> <span class="o">+</span> <span class="n">g2</span><span class="p">)</span> <span class="o">%</span> <span class="mi">6</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">out</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
        <span class="c1"># einsum is so we can do matrix product for elements of f and g,</span>
        <span class="c1"># since we have one matrix per color</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ijk-&gt;ik&quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">z6_prod</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">))),</span> <span class="n">p</span><span class="p">(</span><span class="n">g</span><span class="p">)),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">c</span>

    <span class="k">return</span> <span class="n">out</span>


<span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_phi</span><span class="p">)(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 3.44656211,  1.99816053, -0.63251154])
</pre></div>
</div>
</div>
</div>
<p>At this point, we can now verify that the CNN is equivariant by comparing transforming the input function and the output function. We’ll need to define our function transforms as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">z6_fxn_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">z6_prod</span><span class="p">(</span><span class="n">z6_inv</span><span class="p">(</span><span class="n">g</span><span class="p">),</span> <span class="n">h</span><span class="p">))</span>


<span class="n">z6_fxn</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">z6_fxn</span><span class="p">)(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.10546875, 0.734375  , 0.60546875]),
 array([0.4296875 , 0.10546875, 0.7578125 ]))
</pre></div>
</div>
</div>
</div>
<p>First we’ll compute <span class="math notranslate nohighlight">\(\psi\left[\mathbb{T}_2 f(x)\right]\)</span> – the network acting on the transformed input function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trans_element</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">trans_input_fxn</span> <span class="o">=</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="n">trans_element</span><span class="p">,</span> <span class="n">z6_fxn</span><span class="p">)</span>
<span class="n">trans_input_out</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">trans_input_fxn</span><span class="p">,</span> <span class="n">z6_phi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we compute <span class="math notranslate nohighlight">\(\mathbb{T}_2\psi\left[f(x)\right]\)</span> – the transform acting on the network output</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_fxn</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_phi</span><span class="p">)</span>
<span class="n">trans_output_out</span> <span class="o">=</span> <span class="n">z6_fxn_trans</span><span class="p">(</span><span class="n">trans_element</span><span class="p">,</span> <span class="n">output_fxn</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;g -&gt; psi[f(g)], g -&gt; psi[Tgf(g)], g-&gt; Tg psi[f(g)]&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="n">i</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_phi</span><span class="p">)(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">trans_input_out</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">trans_output_out</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>g -&gt; psi[f(g)], g -&gt; psi[Tgf(g)], g-&gt; Tg psi[f(g)]
0 [ 3.45  2.   -0.63] [ 0.7   1.21 -0.42] [ 0.7   1.21 -0.42]
1 [ 4.03  1.98 -2.56] [ 4.18  3.28 -4.54] [ 4.18  3.28 -4.54]
2 [0.73 2.44 0.14] [ 3.45  2.   -0.63] [ 3.45  2.   -0.63]
3 [ 3.8   1.86 -4.46] [ 4.03  1.98 -2.56] [ 4.03  1.98 -2.56]
4 [ 0.7   1.21 -0.42] [0.73 2.44 0.14] [0.73 2.44 0.14]
5 [ 4.18  3.28 -4.54] [ 3.8   1.86 -4.46] [ 3.8   1.86 -4.46]
</pre></div>
</div>
</div>
</div>
<p>We can see that the outputs indeed match and therefore our network is G-equivariant. One last detail is that it would be nice to visualize this, so we can add a nonlinearity to remap our output back to color space. Our colors should be between 0 and 1, so we can use a sigmoid to put the activations back to valid colors. I’ll hide the input since it contains irrelevant code, but here is the visualization of the previous numbers showing the equivariance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">z6_fxn</span><span class="p">,</span> <span class="n">z6_phi</span><span class="p">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">trans_input_out</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">trans_output_out</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">r</span><span class="s2">&quot;$\psi\left[f(g)\right]$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\psi\left[\mathbb</span><span class="si">{T}</span><span class="s2">_2f(g)\right]$&quot;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s2">&quot;$\mathbb</span><span class="si">{T}</span><span class="s2">_2\psi\left[f(g)\right]$&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">convert_color</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span> <span class="o">**</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="mi">256</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;#</span><span class="si">{:6X}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>


<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c1</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c2</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">c3</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
    <span class="c1"># plt.plot([0, points[0,0]], [0, points[0, 1]], color=&#39;black&#39;, zorder=0)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s2">&quot;equal&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_24_0.png" src="../_images/Equivariant_24_0.png" />
</div>
</div>
<p>As you can see, our output looks the same if we apply the rotation either before or after, so our network is G-equivariant.</p>
</div>
<div class="section" id="g-equivariant-convolutions-with-translation">
<h2><span class="section-number">13.8. </span>G-Equivariant Convolutions with Translation<a class="headerlink" href="#g-equivariant-convolutions-with-translation" title="Permalink to this headline">¶</a></h2>
<p>How can we treat the p4m group? We cannot directly use the continuous convolution definition because the rotations/mirror subgroup is finite and we cannot use the finite convolution because the translation subgroup is locally compact (infinitely many elements). Instead, we will exploit the structure of the group: it is constructed via a semidirect product so each group element is a pair of elements. Namely we can rewrite Equation 8.6 using the constituent subgroups <span class="math notranslate nohighlight">\(N \rtimes H\)</span> and writing elements <span class="math notranslate nohighlight">\(g = hn, g^{-1} = n^{-1}h^{-1}\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Remember that <span class="math notranslate nohighlight">\(g = nh\)</span> is fine to use because <span class="math notranslate nohighlight">\((n, e_r)\cdot (e_n, h) = (n, h)\)</span>, whereas the reverse requires using the conjugation <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span> (not to be confused with the kernel <span class="math notranslate nohighlight">\(\phi(g)\)</span>).</p>
</div>
<div class="amsmath math notranslate nohighlight" id="equation-9d1e94b1-4816-42aa-af22-18f4bd5206fa">
<span class="eqno">(13.12)<a class="headerlink" href="#equation-9d1e94b1-4816-42aa-af22-18f4bd5206fa" title="Permalink to this equation">¶</a></span>\[\begin{equation}
(f * \phi)(u) = \sum_{n \in N}\sum_{h \in H} f\uparrow^G\left(un^{-1}h^{-1}\right)\phi(hn)
\end{equation}\]</div>
<p>Now we must treat the fact that there are an infinite number of elements in <span class="math notranslate nohighlight">\(N\)</span> (the translations). We can simply choose the kernel function (<span class="math notranslate nohighlight">\(\phi\)</span>) to only have support (<span class="math notranslate nohighlight">\(\phi(g) &gt; 0\)</span>) at locations we want and that will simplify the integration. This may seem ad-hoc – but remember we already made choices like not including 45° rotations. There do exist ways to systematically treat how to narrow the kernels into “neigbhorhoods” of groups in <span id="id8">[<a class="reference internal" href="#id103">FSIW20</a>]</span> or you can find a rigorous derivation specifically for p4 in <span id="id9">[<a class="reference internal" href="#id104">RBTH20</a>]</span> or <span id="id10">[<a class="reference internal" href="#id105">CW16</a>]</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>I have a hidden cell below which does a bit of magic. It makes the group elements be hashable. That in turn allows me to cache functions, enabling much faster speeds. This code would be unusable otherwise due to all the nested loops.</p>
</div>
<p>Our goal for the p4m group is image data, so we’ll limit the support of the kernel to only integer translations (like pixels) and limit the distance to 5 units. This simply reduces our sum over the normal subgroup (<span class="math notranslate nohighlight">\(N\)</span>). We can now begin our implementation. We’ll start by loading an image which will serve as our function. It is a <span class="math notranslate nohighlight">\(32\times32\)</span> RGB image. Remember that we need to allow points to have 3 dimensions, where the third dimension is always 1 to accommodate our augmented space.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># From https://gist.github.com/Susensio/61f4fee01150caaac1e10fc5f005eb75</span>

<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span><span class="p">,</span> <span class="n">wraps</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">np_cache</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;LRU cache implementation for functions whose FIRST parameter is a numpy array</span>
<span class="sd">    &gt;&gt;&gt; array = np.array([[1, 2, 3], [4, 5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; @np_cache(maxsize=256)</span>
<span class="sd">    ... def multiply(array, factor):</span>
<span class="sd">    ...     print(&quot;Calculating...&quot;)</span>
<span class="sd">    ...     return factor*array</span>
<span class="sd">    &gt;&gt;&gt; multiply(array, 2)</span>
<span class="sd">    Calculating...</span>
<span class="sd">    array([[ 2,  4,  6],</span>
<span class="sd">           [ 8, 10, 12]])</span>
<span class="sd">    &gt;&gt;&gt; multiply(array, 2)</span>
<span class="sd">    array([[ 2,  4,  6],</span>
<span class="sd">           [ 8, 10, 12]])</span>
<span class="sd">    &gt;&gt;&gt; multiply.cache_info()</span>
<span class="sd">    CacheInfo(hits=1, misses=1, maxsize=256, currsize=1)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">function</span><span class="p">):</span>
        <span class="nd">@wraps</span><span class="p">(</span><span class="n">function</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">np_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">hashable_array</span> <span class="o">=</span> <span class="n">array_to_tuple</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">cached_wrapper</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="nd">@lru_cache</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">cached_wrapper</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hashable_array</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">array_to_tuple</span><span class="p">(</span><span class="n">np_array</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Iterates recursivelly.&quot;&quot;&quot;</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">array_to_tuple</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np_array</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np_array</span>

        <span class="c1"># copy lru_cache attributes over too</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">cache_info</span> <span class="o">=</span> <span class="n">cached_wrapper</span><span class="o">.</span><span class="n">cache_info</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="n">cache_clear</span> <span class="o">=</span> <span class="n">cached_wrapper</span><span class="o">.</span><span class="n">cache_clear</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">decorator</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load image and drop alpha channel</span>
<span class="n">W</span> <span class="o">=</span> <span class="mi">32</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">func_vals</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;quadimg.png&quot;</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="c1"># maybe on google colab</span>
    <span class="kn">import</span> <span class="nn">urllib.request</span>

    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span>
        <span class="s2">&quot;https://raw.githubusercontent.com/whitead/dmol-book/master/dl/quadimg.png&quot;</span><span class="p">,</span>
        <span class="s2">&quot;quadimg.png&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">func_vals</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;quadimg.png&quot;</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="c1"># we pad it with zeros to show boundary</span>
<span class="n">func_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
    <span class="n">func_vals</span><span class="p">,</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">0.2</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">pix_func</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># clip &amp; squeeze &amp; round to account for transformed values</span>
    <span class="n">xclip</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># points are centered, fix that</span>
    <span class="n">xclip</span> <span class="o">+=</span> <span class="p">[</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="c1"># add 1 to account for padding</span>
    <span class="k">return</span> <span class="n">func_vals</span><span class="p">[</span><span class="n">xclip</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xclip</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_func</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">gridx</span><span class="p">,</span> <span class="n">gridy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">indexing</span><span class="o">=</span><span class="s2">&quot;ij&quot;</span>
    <span class="p">)</span>
    <span class="c1"># make it into batched x,y indices and add dummy 1 indices for augmented space</span>
    <span class="n">batched_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">gridy</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">batched_idx</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>


<span class="n">plot_func</span><span class="p">(</span><span class="n">pix_func</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_29_0.png" src="../_images/Equivariant_29_0.png" />
</div>
</div>
<p>Now let’s define our G-function transform so that we can transform our function with group elements. We’ll apply a <span class="math notranslate nohighlight">\(rst_{12,-8}\)</span> element to our function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_h</span><span class="p">(</span><span class="n">rot</span><span class="p">,</span> <span class="n">mirror</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make h subgroup element&quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mirror</span><span class="p">:</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">rot</span><span class="p">),</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">r</span> <span class="o">@</span> <span class="n">m</span>


<span class="k">def</span> <span class="nf">make_n</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make normal subgroup element&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dx</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>


<span class="k">def</span> <span class="nf">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;compute g-function transform&quot;&quot;&quot;</span>

    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="n">ginv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">ginv</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="n">g</span> <span class="o">=</span> <span class="n">make_h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">)</span>
<span class="n">tfunc</span> <span class="o">=</span> <span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pix_func</span><span class="p">)</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">tfunc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_31_0.png" src="../_images/Equivariant_31_0.png" />
</div>
</div>
<p>Now we need to create our lifting and projecting maps to go from functions over points to functions over group elements. Remember, our lifting function just takes the translation element and makes that point.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># enumeraet stabilizer subgrou (rotation/mirrors)</span>
<span class="n">stabilizer</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">stabilizer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">make_h</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">lift</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;lift f into group&quot;&quot;&quot;</span>
    <span class="c1"># create new function from original</span>
    <span class="c1"># that is f(gx_0)</span>
    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">g</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="k">def</span> <span class="nf">project</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;create projected function over space&quot;&quot;&quot;</span>

    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="o">=</span><span class="n">f</span><span class="p">):</span>
        <span class="c1"># x may be batched so we have to allow it to be N x 3</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="c1"># find coset gH</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">make_n</span><span class="p">(</span><span class="n">xi</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xi</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># loop over coset</span>
            <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">stabilizer</span><span class="p">:</span>
                <span class="n">ghi</span> <span class="o">=</span> <span class="n">g</span> <span class="o">@</span> <span class="n">h</span>
                <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">f</span><span class="p">(</span><span class="n">ghi</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="c1"># try them out</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lifted&quot;</span><span class="p">,</span> <span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">)(</span><span class="n">g</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;projected&quot;</span><span class="p">,</span> <span class="n">project</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">))([</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lifted [0.93333334 0.7176471  0.43137255]
projected [[0.72941178 0.71764708 0.72156864]]
</pre></div>
</div>
</div>
</div>
<p>We now need to create our kernel functions <span class="math notranslate nohighlight">\(\phi\)</span>. Rather than make a function of the group elements, we’ll use indices to represent the different group elements. Remember we need to apply a sigmoid at the end so that we stay in color space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel_width</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># must be odd</span>
<span class="c1"># make some random values for kernel (untrained)</span>
<span class="c1"># kernel is group elements x 3 x 3. The group elements are structured (for simplicity) as a N x 5 x 5</span>
<span class="c1"># the 3 x 3 part is because we have 3 color channels coming in and 3 going out.</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">),</span> <span class="n">kernel_width</span><span class="p">,</span> <span class="n">kernel_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">conv</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">kernel</span><span class="p">):</span>
    <span class="nd">@np_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">W</span> <span class="o">**</span> <span class="mi">4</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fxn</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
        <span class="c1"># It is possible to do this without inner for</span>
        <span class="c1"># loops over convolution (use a standard conv),</span>
        <span class="c1"># but we do this for simplicity.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">hi</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stabilizer</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">nix</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">niy</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">result</span> <span class="o">+=</span> <span class="p">(</span>
                        <span class="n">f</span><span class="p">(</span><span class="n">u</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="o">-</span><span class="n">nix</span><span class="p">,</span> <span class="o">-</span><span class="n">niy</span><span class="p">)</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
                        <span class="o">@</span> <span class="n">kernel</span><span class="p">[</span><span class="n">hi</span><span class="p">,</span> <span class="n">nix</span> <span class="o">+</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">niy</span> <span class="o">+</span> <span class="n">kernel_width</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fxn</span>


<span class="c1"># compute convolution</span>
<span class="n">cout</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">))</span>
<span class="c1"># try it out an a group element</span>
<span class="n">cout</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.08769476, 0.82036708, 0.99128031])
</pre></div>
</div>
</div>
</div>
<p>At this point our convolution layer has returned a function over all group elements. We can visualize this by viewing each stabilizer element individually across the normal subgroup. This is like plotting each coset with a choice of representative element.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_coset</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;plot a function over group elements on cosets given representative g&quot;&quot;&quot;</span>
    <span class="n">gridx</span><span class="p">,</span> <span class="n">gridy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">W</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">indexing</span><span class="o">=</span><span class="s2">&quot;ij&quot;</span>
    <span class="p">)</span>
    <span class="c1"># make it into batched x,y indices and add dummy 1 indices for augmented space</span>
    <span class="n">batched_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">gridy</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">gridx</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
    <span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">W</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">bi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batched_idx</span><span class="p">):</span>
        <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">h</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="n">bi</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bi</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>


<span class="c1"># try it with mirror</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plot_coset</span><span class="p">(</span><span class="n">make_h</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">lift</span><span class="p">(</span><span class="n">pix_func</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_37_0.png" src="../_images/Equivariant_37_0.png" />
</div>
</div>
<p>Now we will plot our convolution for each possible coset representative. This code is <em>incredibly</em> inefficient because we have so many loops in plotting and the convolution. This is where the <code class="docutils literal notranslate"><span class="pre">np_cache</span></code> from above helps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stabilizer_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$e$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^2$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^3$&quot;</span><span class="p">,</span> <span class="s2">&quot;$s$&quot;</span><span class="p">,</span> <span class="s2">&quot;$rs$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^2s$&quot;</span><span class="p">,</span> <span class="s2">&quot;$r^3s$&quot;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">stabilizer_names</span><span class="p">,</span> <span class="n">stabilizer</span><span class="p">)):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">plot_coset</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cout</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_39_0.png" src="../_images/Equivariant_39_0.png" />
</div>
</div>
<p>These convolutions are untrained, so it’s sort of a diffuse random combination of pixels. You can see each piece of the function broken out by stabilizer group element (the rotation/mirroring). We can stack multiple layers of these convolution if we wanted. At the end, we want to get back to our space with the projection.
Let us now show our layers are equivariant by applying a G-function transform to input and output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">project</span><span class="p">(</span><span class="n">cout</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\psi\left[f(g)\right]$&quot;</span><span class="p">)</span>

<span class="c1"># make a transformation for visualization purposes</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">make_h</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <span class="n">make_n</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">tfunc</span> <span class="o">=</span> <span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">project</span><span class="p">(</span><span class="n">cout</span><span class="p">))</span>
<span class="n">plot_func</span><span class="p">(</span><span class="n">tfunc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mathbb</span><span class="si">{T}</span><span class="s2">\psi\left[f(g)\right]$&quot;</span><span class="p">)</span>

<span class="n">tcout</span> <span class="o">=</span> <span class="n">project</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">lift</span><span class="p">(</span><span class="n">g_func_trans</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pix_func</span><span class="p">))))</span>

<span class="n">plot_func</span><span class="p">(</span><span class="n">tcout</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\psi\left[\mathbb</span><span class="si">{T}</span><span class="s2">f(g)\right]$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_41_0.png" src="../_images/Equivariant_41_0.png" />
</div>
</div>
<p>This shows that the convolution layer is indeed equivariant. Details not covered here are how to do pooling (if desired) and the choice of non-linearity. You can find more details on this for the p4m group in Cohen et al. <span id="id11">[<a class="reference internal" href="#id105">CW16</a>]</span>. This implementation is also quite slow! Kondor et al. <span id="id12">[<a class="reference internal" href="#id100">KT18</a>]</span> show how you can reduce the number of operations by identifying sparsity in the convolutions.</p>
</div>
<div class="section" id="group-representation">
<h2><span class="section-number">13.9. </span>Group Representation<a class="headerlink" href="#group-representation" title="Permalink to this headline">¶</a></h2>
<p>p4m was an infinite group but we restricted ourselves to a finite subset. Before we can progress to move to truly infinite locally compact groups, like SO(3), we need to learn how to systematically represent the group element binary operation. You can find a detailed description of representation theory in Serre <span id="id13">[<a class="reference internal" href="#id109">Ser77</a>]</span> and it is covered in Zee <span id="id14">[<a class="reference internal" href="#id110">Zee16</a>]</span>. Thus far, we’ve discussed the group actions – how they affect a point. Now we need to describe how to represent them with matrices. This will be a very quick overview of this topic, but representation of groups is a large area with well-established references. There is specifically a great amount of literature about building up these representations, but we’ll try to focus on using them since you generally can look-up the representations for most groups we’ll operate in.</p>
<p>Let us first define a representation on a group:</p>
<div class="admonition-linear-representation-of-a-group admonition">
<p class="admonition-title">Linear Representation of a Group</p>
<p>Let <span class="math notranslate nohighlight">\(G\)</span> be a group on an <span class="math notranslate nohighlight">\(n\)</span>-dimensional vector space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> . A linear representation of <span class="math notranslate nohighlight">\(G\)</span> is a group homomorphism: <span class="math notranslate nohighlight">\(\rho: G \rightarrow GL(m,\mathbb{C})\)</span> where <span class="math notranslate nohighlight">\(GL(m, \mathbb{C})\)</span> is the space of <span class="math notranslate nohighlight">\(m\times m\)</span> square invertible matrices with complex numbers. The representation <span class="math notranslate nohighlight">\(\rho\)</span> should satisfy the following equation</p>
<div class="amsmath math notranslate nohighlight" id="equation-964d083d-76a0-4c65-8456-e7ce2433c6d7">
<span class="eqno">(13.13)<a class="headerlink" href="#equation-964d083d-76a0-4c65-8456-e7ce2433c6d7" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\label{rep-def}
\rho\left(g_1\cdot g_2\right) = \rho\left(g_1\right) \rho\left(g_2\right)\; \forall\, g_1,g_2 \in G
\end{equation}\]</div>
<p>where the term <span class="math notranslate nohighlight">\(\rho\left(g_1\right) \rho\left(g_2\right)\)</span> is a matrix product.</p>
</div>
<p>There are a few things to note about this definition. First, the representation assigns matrices to graph elements in such a way that multiplying matrices gives the same representation as getting the representation of the binary operation (<span class="math notranslate nohighlight">\(\rho\left(g_1\cdot g_2\right)\)</span>). Second, the matrices have to be square and invertible. This follows from the requirement that group elements must have an inverse, so naturally we need invertible matrices. The invertible requirement also means often need to allow complex numbers. Third, the <strong>degree</strong> of the representation (<span class="math notranslate nohighlight">\(m\)</span>) need not be the same size as the vector space.</p>
<p>There is a big detail missing from this definition. Does this have anything to do with how the group element affect a point? No. Consider that <span class="math notranslate nohighlight">\(\rho(g_i) = 1\)</span> is a valid representation, as in it satisfies the definition. Yet <span class="math notranslate nohighlight">\(1\)</span> is not the correct way to transforms points with group elements. If we go further and say that the representation is <em>injective</em> (one to one), then we must have a unique representation for every group element. That is called a <strong>faithful representation</strong>. This is better, but it turns out there are still multiple faithful representations for a group.</p>
<p>Remember the way a group affects a point is a <strong>group action</strong>, which maps from the direct product of <span class="math notranslate nohighlight">\(G, \mathcal{X}\)</span> (i.e., a tuple like <span class="math notranslate nohighlight">\((g_2, x)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>). A group action, if it is linear, can also be a representation. Consider that we write the group action <span class="math notranslate nohighlight">\(\pi\)</span> (how a group element affects a point) as <span class="math notranslate nohighlight">\(\pi(g)(x) = x'\)</span>. You can convert this into a square matrix in <span class="math notranslate nohighlight">\(\mathcal{X}\times\mathcal{X}\)</span> by considering how each element of <span class="math notranslate nohighlight">\(x'\)</span> is affected the element in <span class="math notranslate nohighlight">\(x\)</span>. This matrix can be further shown to be in <span class="math notranslate nohighlight">\(GL(m, \mathcal{X})\)</span> and a representation by relying on its linearity. There isn’t a special word for this, but often groups are defined in terms of these special matrices that both transforms points and are valid representations (e.g., SO(3)). They are then called the <strong>defining representation</strong> or <strong>fundamental representation</strong>.</p>
<p>Let’s now see group representations on the examples above that are both group actions and representations.</p>
<div class="tabbed-set docutils">
<input checked="checked" id="fe08ca5b-9a6e-45bb-b644-6f344af382e0" name="443ed2a4-ea8c-47c1-840a-f9ac5b31459f" type="radio">
</input><label class="tabbed-label" for="fe08ca5b-9a6e-45bb-b644-6f344af382e0">
⬡ Finite Group <span class="math notranslate nohighlight">\(Z_6\)</span> </label><div class="tabbed-content docutils">
<p>Our group action defined above was modular arithmetic, which is not linear and so we cannot use it to construct representation. There are multiple representation for cyclic groups like <span class="math notranslate nohighlight">\(Z_6\)</span>. If you’re comfortable with complex numbers, you can build circulant matrices of <span class="math notranslate nohighlight">\(6\)</span>th roots of unity. If that confuses you, like it does me, then you can also just view this group like a rotation group. Just like how if you rotate enough times you get back to the beginning, you can also use rotation matrices of <span class="math notranslate nohighlight">\(360 / 6 = 60^{\circ}\)</span>. This requires a 2D vector representation though for the space. With this choice, a representation is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{k2\pi}{6} &amp; -\sin\frac{k2\pi}{6}\\
\sin\frac{k2\pi}{6} &amp; \cos\frac{k2\pi}{6}\\
\end{array}\right],\, k \in \left\{0, 1, 2, 3, 4, 5\right\}
\end{split}\]</div>
<p>Let’s verify that this is a representation by checking that <span class="math notranslate nohighlight">\(r^2\cdot\,r^4 = e\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lr}
\cos\frac{4\pi}{6} &amp; -\sin\frac{4\pi}{6}\\
\sin\frac{4\pi}{6} &amp; \cos\frac{4\pi}{6}\\
\end{array}\right]\left[\begin{array}{lr}
\cos\frac{8\pi}{6} &amp; -\sin\frac{k2\pi}{6}\\
\sin\frac{8\pi}{6} &amp; \cos\frac{8\pi}{6}\\
\end{array}\right] = \left[\begin{array}{lr}
\cos\frac{12\pi}{6} &amp; -\sin\frac{12\pi}{6}\\
\sin\frac{12\pi}{6} &amp; \cos\frac{12\pi}{6}\\
\end{array}\right] = \left[\begin{array}{lr}
1 &amp; 0\\
0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>You can also verify that this is a group action by repeated application to the point <span class="math notranslate nohighlight">\((1,0)\)</span>, which will rotate around the unit circle.</p>
</div>
<input id="2652d767-e0f0-4a55-8ac0-66d5dc65c54e" name="443ed2a4-ea8c-47c1-840a-f9ac5b31459f" type="radio">
</input><label class="tabbed-label" for="2652d767-e0f0-4a55-8ac0-66d5dc65c54e">
▩ Locally Compact p4m</label><div class="tabbed-content docutils">
<p>Our group action defined above for the translation elements is not linear. To define a representation, we can use <span class="xref myst"><strong>Affine Matrices</strong></span> which are <span class="math notranslate nohighlight">\(3\times3\)</span> invertible square matrices. That means even though our goal is 2D data, we need to introduce a 3rd dimension: <span class="math notranslate nohighlight">\((x, y, 1)\)</span>. The 3rd dimension is always <span class="math notranslate nohighlight">\(1\)</span> and is called the augmented dimension. To specify a group representation we simply need to multiply an affine matrix for rotation, reflection, and translation (<em>in that order!</em>). These are:</p>
<p>Rotation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
\cos\frac{k\pi}{4} &amp; -\sin\frac{k\pi}{4} &amp; 0\\
\sin\frac{k\pi}{4} &amp; \cos\frac{k\pi}{4} &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right] ,\, k \in \left\{0, 1, 2, 3\right\}
\end{split}\]</div>
<p>Reflection:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
1 &amp; 0 &amp; 0\\
0 &amp; -1 &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>Translation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{lcr}
1 &amp; 0 &amp; \Delta x\\
0 &amp; 1 &amp; \Delta y\\
0 &amp; 0 &amp; 1\\
\end{array}\right]
\end{split}\]</div>
<p>It is a bit more involved to verify this is a group representation, but you can try a few group element products to convince yourself. Do not forget the special homomorphism (conjugate <span class="math notranslate nohighlight">\(\phi(h)(n)\)</span>) for semidirect products when multiplying group element, which ensures the correct behavior if rearrange the order of the matrices.</p>
</div>
<input id="681cfa6b-fbd5-4a74-bd88-f6c0ac482859" name="443ed2a4-ea8c-47c1-840a-f9ac5b31459f" type="radio">
</input><label class="tabbed-label" for="681cfa6b-fbd5-4a74-bd88-f6c0ac482859">
⚽ SO(3) Lie Group</label><div class="tabbed-content docutils">
<p>A representation of the SO(3) lie group is just its usual group action: the product of 3 3D rotation matrices <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span> where <span class="math notranslate nohighlight">\(\alpha, \gamma \in [0, 2\pi], \beta \in [0, \pi]\)</span> and the matrices are defined above.</p>
</div>
</div>
<div class="section" id="irreducible-representations">
<h3><span class="section-number">13.9.1. </span>Irreducible representations<a class="headerlink" href="#irreducible-representations" title="Permalink to this headline">¶</a></h3>
<p>These representations that both describe the group action and how group elements affect on another are typically <strong>reducible</strong>, meaning if you drop the requirement that they also describe group action they can be simplified. The process of reducing representations is again a topic best left to other references <span id="id15">[<a class="reference internal" href="#id109">Ser77</a>]</span>. Each group will have multiple unitary irreducible representations (e.g., <span class="math notranslate nohighlight">\(\phi(g) = 1\)</span> is always a valid irreducible representation). The number of irreducible representations is finite for finite groups and an infinite sequence for locally compact groups. These irreducible representations are like orthonormal basis-functions or basis-vectors from Hilbert spaces. From the Peter-Weyl theorem, they specifically provide a complete basis-set for integrable (<span class="math notranslate nohighlight">\(L^2\)</span>) functions of the group. Recall, we can use lifting to move functions of our space to our group and thus the irreducible representations enable us to represent the functions as a (direct) sum of coefficients of these. One important attribute of irreducible representations is that they can be complex and if a group is non-abelian, some of them will be matrices. That means the individual representations can have different dimensions. Remember, each individual irreducible representation is itself a valid representation but they are not all faithful and so you need some of them to uniquely represent all group elements and all (?) of them to represent functions over the group. We’ll discuss below why we would subject ourself to this confusing and seemingly capricious convention of working with irreducible representations.</p>
<p>There is a (countable) infinite sequence of possible irreducible representations for the SO(3) group known as the Wigner D-matrices. They must be of odd dimension, and so are traditionally written as the sequence <span class="math notranslate nohighlight">\(2l + 1\)</span> where <span class="math notranslate nohighlight">\(l\)</span> is an integer that serves as the irreducible representation index. The Wigner D-matrices are square with dimension <span class="math notranslate nohighlight">\(2l + 1\)</span> and are a function of the group element (e.g., the angles of the rotation). This may be surprising, that the irreducible representations can be of greater dimension than our reducible representation <span class="math notranslate nohighlight">\(R_z(\alpha)R_y(\beta)R_z(\gamma)\)</span>. The easiest way to think about this is to consider SO(3) acting on 3 dimensional <span class="math notranslate nohighlight">\(nth\)</span> degree polynomials. The trivial representation works on 0th degree polynomials (<span class="math notranslate nohighlight">\(l = 0\)</span>), the 3 dimensional representation works on 1st degree polynomials (<span class="math notranslate nohighlight">\(l = 1\)</span>), the 5 dimensional representation works on 2nd degree polynomials (<span class="math notranslate nohighlight">\(l = 2\)</span>), and so on. You can find a nice description of <a class="reference external" href="https://math.stackexchange.com/a/40141">this here</a>.</p>
<p>A sum of irreducible representations is how we encode our input function <span class="math notranslate nohighlight">\(f(x)\)</span> into the group SO(3). The main reason we do this is because <em>convolutions of group functions are products of their irreducible representations</em>. We can replace all the convolutions in Equation 8.7 with products. This is critical, since in SO(3) convolutions require a series of spherical integrals. Removing the integrals means we can do training and inference with equivariant neural networks in SO(3) with existing deep learning frameworks.</p>
<p>Hopefully at this point we have an understanding of representations, irreducible representations, and the point of them. Now we must discuss the numerical details. The first question is how we actually encode our input function into the irreducible representation. One way is via the generalization of the Fourier transform:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d35c5987-0f92-4144-9d3f-da9bebf2c414">
<span class="eqno">(13.14)<a class="headerlink" href="#equation-d35c5987-0f92-4144-9d3f-da9bebf2c414" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\hat{f}(\rho_i) = \int_G\rho_i(u)f\uparrow^G\left(u\right)d\mu(u), \; l=0,1,\ldots,
\end{equation}\]</div>
<p>where the left side is now a sequence of scalars over <span class="math notranslate nohighlight">\(l\)</span>, like a usual Fourier transform, <span class="math notranslate nohighlight">\(\rho_i(u)\)</span> is the <span class="math notranslate nohighlight">\(l\)</span>th irreducible representation, and <span class="math notranslate nohighlight">\(d\mu(u)\)</span> is the Haar measure. The Haar measure for SO(3) in our group representation (<span class="math notranslate nohighlight">\(R_zR_yR_z\)</span>) is <span class="math notranslate nohighlight">\(\frac{1}{8\pi^2}\sin\beta\)</span>.</p>
<p>What does this look like for a typical neural network input? Imagine our features are a single point (non-zero value) along the positive <span class="math notranslate nohighlight">\(x-axis\)</span>. Remember that an input to the SO(3) should lie on the unit sphere, so the point is <span class="math notranslate nohighlight">\((1, 0 ,0)\)</span>. We have to convert this to a function, easy enough: <span class="math notranslate nohighlight">\(f(x, y, z) = \delta(x - 1)\)</span>. Now we must lift this into our group using our stabilizer at the north pole: <span class="math notranslate nohighlight">\(f(g) = f\left(R_z(\alpha)R_y(\beta)R_z(\gamma)\right) = \delta(\beta - \pi / 2)\delta(\alpha)\)</span>. Note our lifted function cannot involve <span class="math notranslate nohighlight">\(\gamma\)</span> because of our convention of lifting with the stabilizer subgroup of the north pole. Now we can compute the integral with the irreducible representations in Equation 13.14. For SO(3), these irreducible representations are the Wigner D-matrices which are square matrices. It would seem then that our output will be a series of square matrices of increasing dimension as <span class="math notranslate nohighlight">\(l\)</span> increases. However, we only require the 0th column of this square matrix because the rest of the terms are zero (Appendix D <span id="id16">[<a class="reference internal" href="#id144">CGKohlerW18</a>]</span>). This yields <span class="math notranslate nohighlight">\(2l + 1\)</span> non-zero terms which is how implementations and papers keep track of them. It turns out the 0th column of the Wigner D-matrices are the <strong>spherical harmonics</strong>!</p>
<p>Adopting the indexing of spherical harmonics (e.g., <span class="math notranslate nohighlight">\(\rho_1^{-1}, \rho_1^{0}, \rho_1^{1}\)</span>), we can compute our <span class="math notranslate nohighlight">\(2l + 1\)</span> terms. For example, here is the first term:</p>
<div class="amsmath math notranslate nohighlight" id="equation-562bd9b7-6d35-4ca3-9681-294e4a69afa4">
<span class="eqno">(13.15)<a class="headerlink" href="#equation-562bd9b7-6d35-4ca3-9681-294e4a69afa4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\hat{f}(\rho_0^0) = \int_0^{2\pi}\int_0^\pi\int_0^{2\pi} \frac{1}{2}\frac{1}{\sqrt{\pi}} \delta(\beta - \pi / 2)\delta(\alpha)\,\frac{1}{8\pi^2}\sin\beta \,d\alpha d\beta d\gamma = \frac{\sqrt{\pi}}{8\pi^2}
\end{equation}\]</div>
<p>As expected, we get out a length 1 vector - one for each irreducible representation matrix column element (spherical harmonic) in the <span class="math notranslate nohighlight">\(l = 0\)</span> set of irreducible representations. Note that depending on your spherical harmonic convention, these scalars will be complex valued.</p>
<hr class="docutils" />
<p>We’ve seen now that we can convert our input functions into a sum of irreducible representations. Once in the irreducible representation, each equivariant layer is now a product of the irreducible representations with a matrix of weights. We have not discussed non-linearities, which are required to make these neural networks able to universally approximate functions. You can see how this approach is used in real models in <span id="id17">[<a class="reference internal" href="data.html#id61">TSK+18</a>]</span> and <span id="id18">[<a class="reference internal" href="#id107">BSS+21</a>]</span>. Another way this approach is used is to encode the edge inputs to a graph neural network with irreducible representations of distance between nodes; this gives you the permutation invariance of a graph neural network and spatial equivariance <span id="id19">[<a class="reference internal" href="gnn.html#id96">KGrossGunnemann20</a>]</span>.</p>
<p>You’ll find a variety of equivariant neural networks and theory in the literature. We saw from the theorem above that they all can be viewed as the G-euivariant convolution layers, which itself is based on Schur’s lemma. So how do the many equivariant neural networks differ? Generally the non-linearities are different. Some use Clebsch-Gordon coefficients and others use gated non-linearities. Both have to be pointwise to avoid mixing representations. Another difference is some use Gauges or Lie groups to develop the theory, but that is equivalent to what we’ve done here. It’s just a bit more structured. Lastly, some have permutation equivariance baked in because they are intended to be used with molecules.</p>
</div>
</div>
<div class="section" id="equivariant-neural-networks-with-constraints">
<h2><span class="section-number">13.10. </span>Equivariant Neural Networks with Constraints<a class="headerlink" href="#equivariant-neural-networks-with-constraints" title="Permalink to this headline">¶</a></h2>
<p>Irreducible representations are a bit of hassle. You need to project your input to them, you can have problems with channels, they require custom implementations, and you need to choose were to truncate your irreducible representations because they are in principle infinite. An interesting way to avoid them is to instead work in the defining representation (dense matrix) and put equivariant constraints on your network weights. This approach is quite nice because the implementation is independent of the group. It also works for finite groups. Its disadvantage appears when we start getting large input spaces, like all the positions of a protein, because it replaces vectors of irreducible reps with matrices which means you have <span class="math notranslate nohighlight">\(M^2\)</span> scaling where <span class="math notranslate nohighlight">\(M\)</span> is the number of input points. Let’s see an example of this approach via the library released by the authors called Equivariant MLP (<code class="docutils literal notranslate"><span class="pre">emlp</span></code>)<span id="id20">[<a class="reference internal" href="#id145">FWW21</a>]</span></p>
<p>We’ll create an SO(3) equivariant neural network and check that it is equivariant to rotations. We begin by defining our group and its representation. I’ll show a few elements too, to demonstrate that this is the faithful representation and not the irreducible.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">emlp.groups</span> <span class="kn">import</span> <span class="n">SO</span><span class="p">,</span> <span class="n">S</span>
<span class="kn">import</span> <span class="nn">emlp.reps</span> <span class="k">as</span> <span class="nn">reps</span>
<span class="kn">import</span> <span class="nn">emlp</span>
<span class="kn">import</span> <span class="nn">haiku</span> <span class="k">as</span> <span class="nn">hk</span>
<span class="kn">import</span> <span class="nn">emlp.nn.haiku</span> <span class="k">as</span> <span class="nn">ehk</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>

<span class="n">so3_rep</span> <span class="o">=</span> <span class="n">reps</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="c1"># grab a random group element</span>
<span class="n">sampled_g</span> <span class="o">=</span> <span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">dense_rep</span> <span class="o">=</span> <span class="n">so3_rep</span><span class="o">.</span><span class="n">rho</span><span class="p">(</span><span class="n">sampled_g</span><span class="p">)</span>
<span class="c1"># check its a member of SO(3)</span>
<span class="c1"># g @ g.T = I</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dense_rep</span> <span class="o">@</span> <span class="n">dense_rep</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 1.0000001e+00 -1.9204201e-08 -1.5588926e-08]
 [-1.9204201e-08  9.9999994e-01  1.8752988e-08]
 [-1.5588926e-08  1.8752988e-08  1.0000000e+00]]
</pre></div>
</div>
</div>
</div>
<p>Now we’ll apply our group element to a point to see it rotate the point. The norm should be unchanged, because it’s a rotation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;new point&quot;</span><span class="p">,</span> <span class="n">dense_rep</span> <span class="o">@</span> <span class="n">point</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">dense_rep</span> <span class="o">@</span> <span class="n">point</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>new point [0.12392607 0.04776323 0.99114126]
norm 1.0
</pre></div>
</div>
</div>
</div>
<p>Now let’s assume our input function consists of 5 points (e.g., methanol molecule) defined by features (e.g., 1D element embedding) and positions. We’ll create that as a direct sum of 5 scalars and 5 vectors. Our output will be a vector (e.g., dipole). Equivariance here will then mean that if rotate the input points, our output vector should undergo the same rotation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_rep</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">so3_rep</span> <span class="o">**</span> <span class="mi">0</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">so3_rep</span> <span class="o">**</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input rep&quot;</span><span class="p">,</span> <span class="n">input_rep</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output rep&quot;</span><span class="p">,</span> <span class="n">so3_rep</span><span class="p">)</span>

<span class="n">input_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input features&quot;</span><span class="p">,</span> <span class="n">input_point</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input positions</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">input_point</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>input rep 5V⁰+5V
output rep V
input features [ 0.61039176 -0.02324598  0.31156184 -0.24726572  0.62837389]
input positions
 [[-1.90765588 -1.3651892   0.68041479]
 [ 0.15247403  0.61504037  0.49317622]
 [ 0.08630656 -0.10590415 -0.11856734]
 [ 0.04371408 -1.63699089 -0.91206895]
 [-0.30897636 -0.64478339 -0.68407274]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">emlp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">EMLP</span><span class="p">(</span><span class="n">input_rep</span><span class="p">,</span> <span class="n">so3_rep</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output_point</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="n">output_point</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>output [-0.00667121 -0.00819823  0.00217276]
</pre></div>
</div>
</div>
</div>
<p>Now we’ll transform the input points according to a random element in the group. We could convert the input into the five spatial vectors and apply the group element to them individually and put them back together. However, <code class="docutils literal notranslate"><span class="pre">emlp</span></code> has a convenience function for exactly that. We can change our group element to the input representation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trans_input_point</span> <span class="o">=</span> <span class="n">input_rep</span><span class="o">.</span><span class="n">rho_dense</span><span class="p">(</span><span class="n">sampled_g</span><span class="p">)</span> <span class="o">@</span> <span class="n">input_point</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;transformed input features&quot;</span><span class="p">,</span> <span class="n">trans_input_point</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;transformed input positions</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">trans_input_point</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>transformed input features [ 0.61039174 -0.02324598  0.31156185 -0.24726571  0.62837386]
transformed input positions
 [[ 0.43986505 -2.2852502   0.7416248 ]
 [-0.41538814  0.43937057  0.5283484 ]
 [ 0.11772156  0.022786   -0.13544431]
 [ 1.3563833  -0.75072896 -1.0536369 ]
 [ 0.3480471  -0.6011482  -0.7047351 ]]
</pre></div>
</div>
</div>
</div>
<p>Now we compare running the transformed input through the model against applying the group element to the output from the untransformed input.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">trans_input_point</span><span class="p">),</span> <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">output_point</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(DeviceArray([ 0.00454526, -0.00956199,  0.00208466], dtype=float32),
 DeviceArray([ 0.00454526, -0.009562  ,  0.00208466], dtype=float32))
</pre></div>
</div>
</div>
</div>
<p>Indeed they are equivalent – meaning this model is equivariant. The constraint approach is quite simple to use and can handle arbitrary groups. However, it may not be efficient when working with many input points (like a protein) and it may make sense to use an implementation specific to E(3) or SO(3).</p>
<div class="section" id="how-the-constraints-work">
<h3><span class="section-number">13.10.1. </span>How the constraints work<a class="headerlink" href="#how-the-constraints-work" title="Permalink to this headline">¶</a></h3>
<p>How does this magic happen? Rather than explicitly setting constraints on the dense layer weights, <code class="docutils literal notranslate"><span class="pre">emlp</span></code> always first projects the network weights into an <strong>equivariant subspace.</strong> This means that the cost of equivariance is paid when constructing the model when this projection matrix is found but not later during training and inference. The equivariant subspace is the space of allowed weights that respect the equivariance. Let’s see what this looks like.</p>
<p>Recall that a dense layer has the equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-be1d9f3c-29d3-46dd-a74b-f53c20dea1ad">
<span class="eqno">(13.16)<a class="headerlink" href="#equation-be1d9f3c-29d3-46dd-a74b-f53c20dea1ad" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \sigma\left(Wx + b\right)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma\)</span> is a special non-linearity for equivariant neural networks we won’t discuss here (see <span id="id21">[<a class="reference internal" href="data.html#id62">WGW+18</a>]</span>). To respect the equivariance, <span class="math notranslate nohighlight">\(W,b\)</span> will need to be projected into an equivariant subspace that depends on our group and input/output representations. So our modified equation would look like:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8bcdae37-0050-4ff7-8c2b-982dea20daff">
<span class="eqno">(13.17)<a class="headerlink" href="#equation-8bcdae37-0050-4ff7-8c2b-982dea20daff" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \sigma\left(P_wWx + P_bb\right)
\end{equation}\]</div>
<p>Let’s start by making these projectors. <span class="math notranslate nohighlight">\(P_b\)</span> only will need to consider the output rep, since <span class="math notranslate nohighlight">\(b\)</span> is the bias (same representation as output).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pw</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_rep</span> <span class="o">&gt;&gt;</span> <span class="n">so3_rep</span><span class="p">)</span><span class="o">.</span><span class="n">equivariant_projector</span><span class="p">()</span>
<span class="n">Pb</span> <span class="o">=</span> <span class="p">(</span><span class="n">so3_rep</span><span class="p">)</span><span class="o">.</span><span class="n">equivariant_projector</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pw shape is&quot;</span><span class="p">,</span> <span class="n">Pw</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;Pb shape is&quot;</span><span class="p">,</span> <span class="n">Pb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pw shape is (60, 60) Pb shape is (3, 3)
</pre></div>
</div>
</div>
</div>
<p>Note that they are square because they should leave the underlying dimension of <span class="math notranslate nohighlight">\(W\)</span> unchanged – we are not projecting to a reduce dimension, but a subspace within the space of possible values of the weights. Remember too our representations are flattened - that 60 comes from the fact that our weight matrix is <span class="math notranslate nohighlight">\(3\times(5 + 15)\)</span>.</p>
<p>Now let’s show how these projectors can convert an arbitrary weight matrix into one that is equivariant.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;W is not alone equivariant&quot;</span><span class="p">,</span>
    <span class="n">W</span> <span class="o">@</span> <span class="n">trans_input_point</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="s2">&quot;!=&quot;</span><span class="p">,</span>
    <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">W</span> <span class="o">@</span> <span class="n">input_point</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W is not alone equivariant [-3.4152575 -1.0510088  6.489844 ] != [ 0.6664303 -0.8329427  4.3918433]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Proj_W</span> <span class="o">=</span> <span class="p">(</span><span class="n">Pw</span> <span class="o">@</span> <span class="n">W</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Projected W is equivariant&quot;</span><span class="p">,</span>
    <span class="n">Proj_W</span> <span class="o">@</span> <span class="n">trans_input_point</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
    <span class="s2">&quot;==&quot;</span><span class="p">,</span>
    <span class="n">sampled_g</span> <span class="o">@</span> <span class="n">Proj_W</span> <span class="o">@</span> <span class="n">input_point</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Projected W is equivariant [-0.1898489  -0.34171456  0.42393818] == [-0.18984881 -0.34171462  0.42393816]
</pre></div>
</div>
</div>
</div>
<p>You may be wondering how much the projection affects <span class="math notranslate nohighlight">\(W\)</span>. Is there enough flexibility that you can learn? We can compare the full <em>random</em> matrix <span class="math notranslate nohighlight">\(W\)</span> vs it’s projection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Random W&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Projected W&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Proj_W</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Equivariant_65_0.png" src="../_images/Equivariant_65_0.png" />
<img alt="../_images/Equivariant_65_1.png" src="../_images/Equivariant_65_1.png" />
</div>
</div>
<p>It appears that there are only a few unique values in <span class="math notranslate nohighlight">\(W\)</span> after projection, so that our weight space is effectively much lower dimensional. This is why it’s important to have multiple channels! This also demonstrates why <code class="docutils literal notranslate"><span class="pre">emlp</span></code> can be more expensive. We’re training 180 values but we could have just used a few. Similarly, the projected bias is zero for our system.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pb</span> <span class="o">@</span> <span class="n">b</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DeviceArray([0., 0., 0.], dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="including-permutation-groups">
<h3><span class="section-number">13.10.2. </span>Including Permutation Groups<a class="headerlink" href="#including-permutation-groups" title="Permalink to this headline">¶</a></h3>
<p>In real molecules, we also need to have permutation equivariance with respect to the atom ordering and bond ordering – which is not true of our above example about computing dipole moment. <code class="docutils literal notranslate"><span class="pre">emlp</span></code> also supports permutation groups, which are usually written as <span class="math notranslate nohighlight">\(S_n\)</span>, where <span class="math notranslate nohighlight">\(n\)</span> is the number of permutable elements in the group. We can make a product group of SO(3) with <span class="math notranslate nohighlight">\(S_5\)</span> to enable permtuation of the atom ordering. One detail is that we no longer will have 5 input features because our space is <span class="math notranslate nohighlight">\(5 \times 3\)</span> – we need to always work with all points simultaneously.</p>
<p>Our input representation will be a 1 channel <span class="math notranslate nohighlight">\(S_5\)</span> feature that represents element of the atom (e.g., via an embedding) and the 3D coordinates of the 5 atoms. The output representation will be a member of the group SO(3)<span class="math notranslate nohighlight">\(\times S_5\)</span> and we will sum over the permutation group to get the dipole moment, which is only a member of SO(3) group.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make product group</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">S</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">*</span> <span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">reps</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="c1"># element + coorindates</span>
<span class="n">Vin</span> <span class="o">=</span> <span class="n">reps</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">S</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">+</span> <span class="n">W</span>
<span class="n">Vout</span> <span class="o">=</span> <span class="n">W</span>
</pre></div>
</div>
</div>
</div>
<p>To include the averaging step, I’ll define a new function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make model</span>
<span class="n">s5_emlp_model</span> <span class="o">=</span> <span class="n">emlp</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">EMLP</span><span class="p">(</span><span class="n">Vin</span><span class="p">,</span> <span class="n">Vout</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="n">G</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">s5_model</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">s5_emlp_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s compare the original and new model to see if the new one is permutation equivariant. We’ll permute the input point but we need to do some reshaping because the input point is a direct sum of the elements (5 things) and the coordinates (15 things)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_perm</span> <span class="o">=</span> <span class="n">S</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">random_rot</span> <span class="o">=</span> <span class="n">SO</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="c1"># break into components</span>
<span class="n">input_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Vin</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="n">ielem</span><span class="p">,</span> <span class="n">icoords</span> <span class="o">=</span> <span class="n">input_point</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span> <span class="n">input_point</span><span class="p">[</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">perm_ielem</span><span class="p">,</span> <span class="n">perm_icoords</span> <span class="o">=</span> <span class="n">random_perm</span> <span class="o">@</span> <span class="n">ielem</span><span class="p">,</span> <span class="n">random_perm</span> <span class="o">@</span> <span class="n">icoords</span>
<span class="n">perm_input_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">perm_ielem</span><span class="p">,</span> <span class="n">perm_icoords</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
<span class="n">rot_perm_input_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
    <span class="p">(</span><span class="n">perm_ielem</span><span class="p">,</span> <span class="p">(</span><span class="n">random_rot</span> <span class="o">@</span> <span class="n">perm_icoords</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Non S5 equivariant: </span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">perm_input_point</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Non S5 equivariant: [-0.00310744  0.01351042  0.01055139] != [ 0.00372788 -0.00727802  0.00273751]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s5_model</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DeviceArray([9.426940e-07, 8.704724e-07, 2.083098e-06], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;S5 equivariant: </span><span class="si">{</span><span class="n">s5_model</span><span class="p">(</span><span class="n">input_point</span><span class="p">)</span><span class="si">}</span><span class="s2"> == </span><span class="si">{</span><span class="n">s5_model</span><span class="p">(</span><span class="n">perm_input_point</span><span class="p">)</span><span class="si">}</span><span class="s2"> == </span><span class="si">{</span><span class="n">s5_model</span><span class="p">(</span><span class="n">rot_perm_input_point</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>S5 equivariant: [9.426940e-07 8.704724e-07 2.083098e-06] == [9.426941e-07 8.704730e-07 2.083098e-06] == [-1.9647100e-06  3.5238935e-07  1.4147206e-06]
</pre></div>
</div>
</div>
</div>
<p>We now have a model that is permutation invariant and rotation equivariant. It is not trained, but it can be now.</p>
</div>
</div>
<div class="section" id="chapter-summary">
<h2><span class="section-number">13.11. </span>Chapter Summary<a class="headerlink" href="#chapter-summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Equivariant neural networks guarantee equivariance by construction for arbitrary groups, which removes the need to align trajectories, work in special coordinate systems, or use pairwise distances.</p></li>
<li><p>Equivariance can be achieved by parameter sharing or testing/training data augmentation, but here we focused on equivariant layers that can be composed into a neural network.</p></li>
<li><p>Equivariance requires definition of a group and homogeneous space. We must view our input data as functions and our models as operators that transform functions.</p></li>
<li><p>Finite groups can be treated with G-equivariant layers that have an additional sum across the number of group elements.</p></li>
<li><p>Infinite groups like SO(3) can be made finite by working with a direct sum (list of vectors) of the irreducible representations. This requires converting the input data though to the irreducible representation and there are complexities in non-linearities and implementations typically must be written per-group.</p></li>
<li><p>Constraint-based equivariant layers are flexible, general, and quick to implement but may not scale well with respect to size of input group or number of points.</p></li>
<li><p>Recent work has also shown you can put irreducible representation direct sums into the edges of graph neural networks, gaining input size independence, permutation invariance, and spatial equivariance in one model.</p></li>
</ul>
</div>
<div class="section" id="relevant-videos">
<h2><span class="section-number">13.12. </span>Relevant Videos<a class="headerlink" href="#relevant-videos" title="Permalink to this headline">¶</a></h2>
<div class="section" id="intro-to-geometric-deep-learning">
<h3><span class="section-number">13.12.1. </span>Intro to Geometric Deep Learning<a class="headerlink" href="#intro-to-geometric-deep-learning" title="Permalink to this headline">¶</a></h3>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/w6Pw4MOzMuo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="section" id="equivariant-networks">
<h3><span class="section-number">13.12.2. </span>Equivariant Networks<a class="headerlink" href="#equivariant-networks" title="Permalink to this headline">¶</a></h3>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/VN2biLjqJXc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
</div>
<div class="section" id="cited-references">
<h2><span class="section-number">13.13. </span>Cited References<a class="headerlink" href="#cited-references" title="Permalink to this headline">¶</a></h2>
<p id="id22"><dl class="citation">
<dt class="label" id="id90"><span class="brackets"><a class="fn-backref" href="#id19">KGrossGunnemann20a</a></span></dt>
<dd><p>Johannes Klicpera, Janek Groß, and Stephan Günnemann. Directional message passing for molecular graphs. In <em>International Conference on Learning Representations</em>. 2020.</p>
</dd>
<dt class="label" id="id66"><span class="brackets"><a class="fn-backref" href="#id17">TSK+18</a></span></dt>
<dd><p>Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: rotation-and translation-equivariant neural networks for 3d point clouds. <em>arXiv preprint arXiv:1802.08219</em>, 2018.</p>
</dd>
<dt class="label" id="id67"><span class="brackets"><a class="fn-backref" href="#id21">WGW+18</a></span></dt>
<dd><p>Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3d steerable cnns: learning rotationally equivariant features in volumetric data. In <em>Advances in Neural Information Processing Systems</em>, 10381–10392. 2018.</p>
</dd>
<dt class="label" id="id103"><span class="brackets">FSIW20</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id8">2</a>)</span></dt>
<dd><p>Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data. <em>arXiv preprint arXiv:2002.12880</em>, 2020.</p>
</dd>
<dt class="label" id="id101"><span class="brackets"><a class="fn-backref" href="#id1">CGW19</a></span></dt>
<dd><p>Taco S Cohen, Mario Geiger, and Maurice Weiler. A general theory of equivariant cnns on homogeneous spaces. <em>Advances in neural information processing systems</em>, 32:9145–9156, 2019.</p>
</dd>
<dt class="label" id="id100"><span class="brackets">KT18</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id7">2</a>,<a href="#id12">3</a>)</span></dt>
<dd><p>Risi Kondor and Shubhendu Trivedi. On the generalization of equivariance and convolution in neural networks to the action of compact groups. In <em>International Conference on Machine Learning</em>, 2747–2755. 2018.</p>
</dd>
<dt class="label" id="id113"><span class="brackets"><a class="fn-backref" href="#id1">LW20</a></span></dt>
<dd><p>Leon Lang and Maurice Weiler. A wigner-eckart theorem for group equivariant convolution kernels. <em>arXiv preprint arXiv:2010.10952</em>, 2020.</p>
</dd>
<dt class="label" id="id145"><span class="brackets">FWW21</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id20">2</a>)</span></dt>
<dd><p>Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equivariant multilayer perceptrons for arbitrary matrix groups. <em>Arxiv</em>, 2021.</p>
</dd>
<dt class="label" id="id106"><span class="brackets"><a class="fn-backref" href="#id2">WAR20</a></span></dt>
<dd><p>Renhao Wang, Marjan Albooyeh, and Siamak Ravanbakhsh. Equivariant maps for hierarchical structures. <em>arXiv preprint arXiv:2006.03627</em>, 2020.</p>
</dd>
<dt class="label" id="id107"><span class="brackets">BSS+21</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id18">2</a>)</span></dt>
<dd><p>Simon Batzner, Tess E. Smidt, Lixin Sun, Jonathan P. Mailoa, Mordechai Kornbluth, Nicola Molinari, and Boris Kozinsky. Se(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. <em>arXiv preprint arXiv:2101.03164</em>, 2021.</p>
</dd>
<dt class="label" id="id108"><span class="brackets"><a class="fn-backref" href="#id4">KGrossGunnemann20b</a></span></dt>
<dd><p>Johannes Klicpera, Janek Groß, and Stephan Günnemann. Directional message passing for molecular graphs. <em>arXiv preprint arXiv:2003.03123</em>, 2020.</p>
</dd>
<dt class="label" id="id157"><span class="brackets"><a class="fn-backref" href="#id5">SHF+21</a></span></dt>
<dd><p>Victor Garcia Satorras, Emiel Hoogeboom, Fabian B. Fuchs, Ingmar Posner, and Max Welling. E(n) equivariant normalizing flows for molecule generation in 3d. <em>arXiv preprint arXiv:2105.09016</em>, 2021.</p>
</dd>
<dt class="label" id="id110"><span class="brackets">Zee16</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id14">2</a>)</span></dt>
<dd><p>Anthony Zee. <em>Group theory in a nutshell for physicists</em>. Princeton University Press, 2016.</p>
</dd>
<dt class="label" id="id104"><span class="brackets"><a class="fn-backref" href="#id9">RBTH20</a></span></dt>
<dd><p>David W Romero, Erik J Bekkers, Jakub M Tomczak, and Mark Hoogendoorn. Attentive group equivariant convolutional networks. <em>arXiv</em>, pages arXiv–2002, 2020.</p>
</dd>
<dt class="label" id="id105"><span class="brackets">CW16</span><span class="fn-backref">(<a href="#id10">1</a>,<a href="#id11">2</a>)</span></dt>
<dd><p>Taco Cohen and Max Welling. Group equivariant convolutional networks. In <em>International conference on machine learning</em>, 2990–2999. 2016.</p>
</dd>
<dt class="label" id="id109"><span class="brackets">Ser77</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Jean-Pierre Serre. <em>Linear representations of finite groups</em>. Volume 42. Springer, 1977.</p>
</dd>
<dt class="label" id="id144"><span class="brackets"><a class="fn-backref" href="#id16">CGKohlerW18</a></span></dt>
<dd><p>Taco S Cohen, Mario Geiger, Jonas Köhler, and Max Welling. Spherical cnns. In <em>International Conference on Learning Representations</em>. 2018.</p>
</dd>
</dl>
</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./dl"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="flows.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">12. </span>Normalizing Flows</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="NLP.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">14. </span>Natural Language Processing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Andrew D. White<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            <a href="http://thewhitelab.org">thewhitelab.org</a> <div id="wh-modal"> <button class="wh-venti-button" aria-label="close modal" id="wh-modal-close">✕</button> <img id="wh-modal-img"> </div>
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>